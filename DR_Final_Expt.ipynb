{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Recommendation-System-Project/Recommendation-system/blob/main/DR_Final_Expt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d8ad3d9a",
      "metadata": {
        "id": "d8ad3d9a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from matplotlib import style\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42098615",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "42098615"
      },
      "outputs": [],
      "source": [
        "# def get_data(sample_num=2000):\n",
        "#     observed_r = np.random.uniform(low=0, high=5, size=(sample_num,)) # observed_r\n",
        "#     predicted_r = np.random.uniform(low=0, high=5, size=(sample_num,)) # predicted rating\n",
        "# #     imputed_e = np.power((predicted_r - 0.5), 2)*0.3 ## e_hat_ui = 0.3*(r_ui - 0.5)^2\n",
        "    \n",
        "#     observed_e = predicted_r - observed_r # e_ui\n",
        "#     propensities = np.random.uniform(low=0, high=1, size=(sample_num,)) # propensities for observed X_ui\n",
        "   \n",
        "#     return observed_r, predicted_r, observed_e, propensities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f8a50cbe",
      "metadata": {
        "id": "f8a50cbe"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    observed_r = pd.read_csv(\"preproceed_data/rating_pairs.csv\").drop(\"user_id\", axis = 1) # observed ratings\n",
        "    observed_r.columns = range(1,len(observed_r.columns)+1)\n",
        "    \n",
        "    predicted_r = pd.DataFrame(np.random.randint(1,5,size=observed_r.shape)) # predicted rating\n",
        "    predicted_r.columns = range(1,len(predicted_r.columns)+1)\n",
        "    \n",
        "    observed_e = predicted_r - observed_r # e_ui\n",
        "    propensities = pd.read_csv(\"preproceed_data/propensities.csv\", header = None) # propensities for all user item pairs\n",
        "    propensities.columns = range(1,len(propensities.columns)+1)\n",
        "    \n",
        "    O_mask = pd.read_csv(\"preproceed_data/O_mask.csv\").drop(\"user_id\", axis = 1)\n",
        "    O_mask.columns = range(1,len(O_mask.columns)+1)\n",
        "\n",
        "    item_features = np.array(pd.read_csv(\"preproceed_data/item_features.csv\", header = None))\n",
        "    user_features = np.array(pd.read_csv(\"preproceed_data/user_features.csv\", header = None))\n",
        "   \n",
        "    return observed_r, predicted_r, observed_e, propensities, O_mask, item_features, user_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5fe3245",
      "metadata": {
        "code_folding": [],
        "id": "d5fe3245"
      },
      "outputs": [],
      "source": [
        "def SGD(predicted_r,\n",
        "        observed_e,\n",
        "        propensities,\n",
        "        step_size=2,\n",
        "        max_iter_count=2000):\n",
        "\n",
        "    m = predicted_r.shape[0]\n",
        "    var = 1\n",
        "    loss = 1\n",
        "    iter_count = 0\n",
        "    iter_list = []\n",
        "    loss_list = []\n",
        "    theta1 = []\n",
        "    theta2 = []\n",
        "    theta = [2.2, 0.58]\n",
        "\n",
        "    \n",
        "    while loss > 0.01 and iter_count < max_iter_count:\n",
        "        loss = 0\n",
        "        theta1.append(theta[0])\n",
        "        theta2.append(theta[1])\n",
        "        rand1 = np.random.randint(0, m, 1)\n",
        "\n",
        "        gradient_w = 2 * predicted_r[rand1] * (\n",
        "            2 * theta[1] - predicted_r[rand1]) * (\n",
        "                (2 * predicted_r[rand1] * theta[1] - predicted_r[rand1]**2) *\n",
        "                theta[0] + observed_e[rand1] - theta[1]**2) / propensities[rand1]\n",
        "\n",
        "        gradient_y = 4 * (theta[1] - theta[0] * predicted_r[rand1]) * (\n",
        "            theta[1]**2 - 2 * predicted_r[rand1] * theta[0] * theta[1] -\n",
        "            observed_e[rand1] + theta[0] * predicted_r[rand1]**2) / propensities[rand1]\n",
        "        \n",
        "        gradient = [gradient_w, gradient_y]\n",
        "        \n",
        "        for i in range(len(theta)):\n",
        "            theta[i] = theta[i] - step_size * gradient[i]\n",
        "        h = np.power((predicted_r - theta[1]), 2) * theta[0]\n",
        "        \n",
        "        for i in range(m):\n",
        "            every_loss = np.power((h[i] - observed_e[i]), 2) / propensities[i]\n",
        "            loss = loss + every_loss\n",
        "\n",
        "        print(\"iter_count: \", iter_count, \"the loss: \",loss)\n",
        "        print(\"theta:\", theta, \"gradient: \", gradient)\n",
        "\n",
        "        iter_list.append(iter_count)\n",
        "        loss_list.append(loss)\n",
        "\n",
        "        iter_count += 1\n",
        "\n",
        "    plt.plot(iter_list, loss_list)\n",
        "    plt.xlabel(\"iter\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.show()\n",
        "    return theta1, theta2, theta, loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9db1aad1",
      "metadata": {
        "id": "9db1aad1"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    observed_r, predicted_r, observed_e, propensities, O_mask, item_features, user_features = get_data()\n",
        "    \n",
        "    # condense data into 1d array with only observed O(u,i)\n",
        "    observed_r_1d = np.array(observed_r*O_mask).flatten()\n",
        "    observed_r_1d = observed_r_1d[~np.isnan(observed_r_1d)]\n",
        "\n",
        "    predicted_r_1d = np.array(predicted_r*O_mask).flatten()\n",
        "    predicted_r_1d = predicted_r_1d[predicted_r_1d != 0]\n",
        "    \n",
        "    observed_e_1d = np.array(observed_e).flatten()\n",
        "    observed_e_1d = observed_e_1d[~np.isnan(observed_e_1d)]\n",
        "    \n",
        "    propensities_1d = np.array(propensities*O_mask).flatten()\n",
        "    propensities_1d = propensities_1d[propensities_1d != 0]\n",
        "\n",
        "    # creating features for all user-item pairs\n",
        "    observation_matrix = []\n",
        "    for u in range(user_features.shape[0]):\n",
        "      for i in range(item_features.shape[0]):\n",
        "        user_f = user_features[u]\n",
        "        item_f = item_features[i]\n",
        "        observed = np.concatenate((user_f, item_f))\n",
        "        observation_matrix.append(observed)\n",
        "    observation_matrix = np.array(observation_matrix)\n",
        "\n",
        "    # select features for only observed user-item pairs\n",
        "    O_mask_1d = np.array(O_mask).flatten()\n",
        "    observed_features = []\n",
        "    for i in range(len(O_mask_1d)):\n",
        "      if O_mask_1d[i] == 1:\n",
        "        observed_features.append(observation_matrix[i])\n",
        "    observed_features = np.array(observed_features)\n",
        "\n",
        "    \n",
        "    # start = time.time()\n",
        "    # theta1,theta2,theta,loss_list = SGD(predicted_r_1d, observed_e_1d, propensities_1d, step_size = 0.0001)\n",
        "    # end = time.time()\n",
        "    \n",
        "    # print(\"The time of execution of above program is :\", end-start)\n",
        "    # print(\"theta for imputation error: \", theta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "560fa7dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "560fa7dd",
        "outputId": "ec20a0b2-ce49-4a02-c400-6905ed729a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "from itertools import count # 迭代器\n",
        "from collections import defaultdict # 使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict\n",
        "from scipy.sparse import csr # csr_matrix，全名为Compressed Sparse Row，是按行对矩阵进行压缩的。CSR需要三类数据：数值，列号，以及行偏移量。CSR是一种编码的方式，其中，数值与列号的含义，与coo里是一致的。行偏移表示某一行的第一个元素在values里面的起始偏移位置。 \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tqdm import tqdm_notebook as tqdm # 可以显示循环的进度条的库"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = observed_features\n",
        "y_train = observed_r_1d"
      ],
      "metadata": {
        "id": "G2M9k20PsSs9"
      },
      "id": "G2M9k20PsSs9",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n,p = x_train.shape\n",
        "\n",
        "k = 10\n",
        "\n",
        "x = tf.placeholder('float',[None,p])\n",
        "\n",
        "y = tf.placeholder('float',[None,1])\n",
        "\n",
        "w0 = tf.Variable(tf.zeros([1]))\n",
        "w = tf.Variable(tf.zeros([p]))\n",
        "\n",
        "v = tf.Variable(tf.random_normal([k,p],mean=0,stddev=0.01))\n",
        "\n",
        "#y_hat = tf.Variable(tf.zeros([n,1]))\n",
        "\n",
        "linear_terms = tf.add(w0,tf.reduce_sum(tf.multiply(w,x),1,keep_dims=True)) # n * 1\n",
        "pair_interactions = 0.5 * tf.reduce_sum(\n",
        "    tf.subtract(\n",
        "        tf.pow(\n",
        "            tf.matmul(x,tf.transpose(v)),2),\n",
        "        tf.matmul(tf.pow(x,2),tf.transpose(tf.pow(v,2)))\n",
        "    ),axis = 1 , keep_dims=True)\n",
        "\n",
        "y_hat = tf.add(linear_terms,pair_interactions)"
      ],
      "metadata": {
        "id": "EKEoWIJcsGyH"
      },
      "id": "EKEoWIJcsGyH",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_w = tf.constant(0.001,name='lambda_w')\n",
        "lambda_v = tf.constant(0.001,name='lambda_v')\n",
        "\n",
        "l2_norm = tf.reduce_sum(\n",
        "    tf.add(\n",
        "        tf.multiply(lambda_w,tf.pow(w,2)),\n",
        "        tf.multiply(lambda_v,tf.pow(v,2))\n",
        "    )\n",
        ")\n",
        "\n",
        "error = tf.reduce_mean(tf.square(y-y_hat))\n",
        "loss = tf.add(error,l2_norm)\n",
        "\n",
        "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
      ],
      "metadata": {
        "id": "PqLYJTQTz_yr"
      },
      "id": "PqLYJTQTz_yr",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "# Launch the graph\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "\n",
        "  print(sess.run([train_op, loss], feed_dict={x: x_train.reshape(-1, p), y: y_train.reshape(-1, 1)}))\n",
        "    \n",
        "\n",
        "  errors = sess.run(error,feed_dict={x: x_train.reshape(-1, p), y: y_train.reshape(-1, 1)})\n",
        "  print(errors)\n",
        "  RMSE = np.sqrt(np.array(errors).mean())\n",
        "  print(RMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIrGPEDu0FMp",
        "outputId": "ef6ce003-5681-452b-c441-0aeb3d81ba16"
      },
      "id": "mIrGPEDu0FMp",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 1172.995]\n",
            "4.3604674e+19\n",
            "6603383300.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "DR_Final_Expt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}