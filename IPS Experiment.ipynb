{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bc2d88",
   "metadata": {},
   "source": [
    "# IPS Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd209b63",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4652260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c435340",
   "metadata": {},
   "source": [
    "增加噪音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcf9808",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Jitter:\n",
    "    def __init__(self, cut_off, num_users, num_items):\n",
    "        self.jitter = 1e-7 * numpy.random.standard_normal((num_users, num_items))\n",
    "        discountParams = 2.0 + numpy.array(range(num_items), dtype = numpy.longdouble)\n",
    "        self.discountParams = numpy.reciprocal(numpy.log2(discountParams))\n",
    "        self.cutOff = min(cut_off, num_items)\n",
    "        self.discountParams[self.cutOff:] = 0.0\n",
    "\n",
    "        print (\"Jitter.init: [DBG]\\t (NumUsers, NumItems)\"), num_users, num_items, (\"\\t Sum DiscountFactors\"),\\\n",
    "                self.discountParams.sum(dtype = numpy.longdouble), (\"\\t [Requested/Set] Cut-off:\"), \\\n",
    "                cut_off, self.cutOff\n",
    "\n",
    "    def rank(self, predicted_matrix):\n",
    "        transformedPredictions = -numpy.ma.add(predicted_matrix, self.jitter)\n",
    "        sortedPredictions = numpy.ma.argsort(transformedPredictions, axis = 1)\n",
    "        return sortedPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050ab6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgJitter = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540a54f",
   "metadata": {},
   "source": [
    "设置propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386c74ff",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose = False):\n",
    "    numObservations = numpy.ma.count(observed_ratings)\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "    inversePropensities = None\n",
    "    if inverse_propensities is None: # 初始化inverse_propensities\n",
    "        inversePropensities = numpy.ones((numUsers, numItems), dtype = numpy.longdouble) * scale /\\\n",
    "                            numObservations\n",
    "    else: # 将inverse_propensities存入array\n",
    "        inversePropensities = numpy.array(inverse_propensities, dtype = numpy.longdouble, copy = True)\n",
    "    \n",
    "    # 提取inversePropensities中仅包含observed的子集\n",
    "    inversePropensities = numpy.ma.array(inversePropensities, dtype = numpy.longdouble, copy = False, \n",
    "                            mask = numpy.ma.getmask(observed_ratings), fill_value = 0, hard_mask = True)\n",
    " \n",
    "    if verbose: #输出结果\n",
    "        print (\"Metrics.SET_PROPENSITIES: [LOG]\\t NumUsers, NumItems, NumObservations\",\n",
    "            numUsers, numItems, numObservations)\n",
    "        print (\"Metrics.SET_PROPENSITIES: [DBG]\\t Sum of observed inverse propensities \",\n",
    "            numpy.ma.sum(inversePropensities, dtype = numpy.longdouble),\n",
    "            (\"(=? NumUsers * NumItems)\"), numUsers * numItems)\n",
    "\n",
    "    return inversePropensities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ee530",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994f62c0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MSE'):\n",
    "    delta = numpy.ma.subtract(predicted_ratings, observed_ratings) # 预测与观测的差值\n",
    "    rectifiedDelta = None # MAE 或 MSE\n",
    "    if mode == 'MSE':\n",
    "        rectifiedDelta = numpy.square(delta)\n",
    "    elif mode == 'MAE':\n",
    "        rectifiedDelta = numpy.ma.abs(delta)\n",
    "    else:\n",
    "        print (\"Metrics.ITEMWISE_METRICS: [ERR]\\t Unrecognized itemwise metric \", mode)\n",
    "        sys.exit(0)\n",
    "\n",
    "    # 根据输入设置propensity\n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
    "\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "\n",
    "    # IP = 1/P(u,i)\n",
    "    observedError = numpy.ma.multiply(rectifiedDelta, inversePropensities) # 观测误差 = 误差函数(如MSE)*IP\n",
    "    cumulativeError = numpy.ma.sum(observedError, dtype = numpy.longdouble) # 累计误差 = sum(观测误差)\n",
    "    vanillaMetric = cumulativeError / scale #  metric = (1/(U*I)) * (1/P(U,I))sum(观测误差) \n",
    "    # 公式参照slides第九页\n",
    "    #标准化\n",
    "    globalNormalizer = numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "    selfNormalizedMetric = cumulativeError / globalNormalizer\n",
    "    \n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perUserError = numpy.ma.sum(observedError, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserEstimate = numpy.ma.divide(perUserError, perUserNormalizer)\n",
    "    userNormalizedMetric = numpy.ma.sum(perUserEstimate, dtype = numpy.longdouble) / numUsers\n",
    "\n",
    "    perItemNormalizer = numpy.ma.sum(inversePropensities, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemNormalizer = numpy.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perItemError = numpy.ma.sum(observedError, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemEstimate = numpy.ma.divide(perItemError, perItemNormalizer)\n",
    "    itemNormalizedMetric = numpy.ma.sum(perItemEstimate, dtype = numpy.longdouble) / numItems\n",
    "   \n",
    "    if verbose:\n",
    "        print (\"Metrics.ITEMWISE_METRICS: [LOG]\\t Vanilla, SelfNormalized, UserNormalized, ItemNormalized\",\n",
    "            vanillaMetric, selfNormalizedMetric, userNormalizedMetric, itemNormalizedMetric)\n",
    "\n",
    "    return vanillaMetric, selfNormalizedMetric, userNormalizedMetric, itemNormalizedMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267ab891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(observed_ratings, predicted_ratings, inverse_propensities, verbose = False):\n",
    "    return ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7db392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(observed_ratings, predicted_ratings, inverse_propensities, verbose = False):\n",
    "    return ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5a76d",
   "metadata": {},
   "source": [
    "DCG(Discounted cumulative gain)折扣累计收益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f043fac",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def DCG(observed_ratings, predicted_ratings, inverse_propensities, cut_off = 50, verbose = False):\n",
    "    global dcgJitter\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "\n",
    "    if dcgJitter is None or dcgJitter.cutOff != cut_off:\n",
    "        dcgJitter = Jitter(cut_off, numUsers, numItems)\n",
    " \n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
    "    \n",
    "    predictedRankings = dcgJitter.rank(predicted_ratings)\n",
    "    weightedGain = numpy.ma.multiply(observed_ratings, inversePropensities)\n",
    " \n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    staticIndices = numpy.ogrid[0:numUsers, 0:numItems]\n",
    "    rankedGains = weightedGain[staticIndices[0], predictedRankings]\n",
    "    perUserDCG = numpy.ma.dot(rankedGains, dcgJitter.discountParams)\n",
    "\n",
    "    dcgValue = numpy.ma.sum(perUserDCG, dtype = numpy.longdouble) / numUsers\n",
    "    snDCGValue = dcgValue * scale / numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "\n",
    "    perUserNormalizedEstimates = numpy.ma.divide(perUserDCG, perUserNormalizer)\n",
    "    uDCGValue = numItems * numpy.ma.sum(perUserNormalizedEstimates, dtype = numpy.longdouble) / numUsers\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"Metrics.DCG: [LOG]\\t DCG, SN-DCG, UN-DCG, IN-DCG\"), dcgValue, snDCGValue, uDCGValue, 0.0\n",
    "    return dcgValue, snDCGValue, uDCGValue, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba4df0",
   "metadata": {},
   "source": [
    "CG(Cumulative Gain)累计收益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ee911a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def CG(observed_ratings, selected_items, inverse_propensities, verbose = False):\n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
    "\n",
    "    clippedSelections = numpy.clip(selected_items, 0, 1)\n",
    "    weightedGain = numpy.ma.multiply(observed_ratings, inversePropensities)\n",
    "    cumulativeGain = numpy.ma.multiply(weightedGain, clippedSelections)\n",
    "    \n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "\n",
    "    globalGain = numpy.ma.sum(cumulativeGain, dtype = numpy.longdouble)\n",
    "    globalNormalizer = numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "\n",
    "    cg = globalGain / numUsers\n",
    "    snCG = numItems * globalGain / globalNormalizer\n",
    "\n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perUserGain = numpy.ma.sum(cumulativeGain, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserEstimate = numpy.ma.divide(perUserGain, perUserNormalizer)\n",
    "    unCG = numItems * numpy.ma.sum(perUserEstimate, dtype = numpy.longdouble) / numUsers\n",
    "\n",
    "    perItemNormalizer = numpy.ma.sum(inversePropensities, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemNormalizer = numpy.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perItemGain = numpy.ma.sum(cumulativeGain, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemEstimate = numpy.ma.divide(perItemGain, perItemNormalizer)\n",
    "    inCG = numpy.ma.sum(perItemEstimate, dtype = numpy.longdouble)\n",
    "       \n",
    "    if verbose:\n",
    "        print (\"Metrics.CG: [LOG]\\t CG, SN-CG, UN-CG, IN-CG\"), cg, snCG, unCG, inCG\n",
    "    return cg, snCG, unCG, inCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6467389",
   "metadata": {},
   "source": [
    "Metric 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2332a822",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAIN]\t True ratings:\n",
      "[[3 3 0]\n",
      " [0 0 2]\n",
      " [0 0 2]\n",
      " [3 0 2]\n",
      " [0 3 2]]\n",
      "[MAIN]\t Predicted ratings:\n",
      "[[0 3 2]\n",
      " [2 3 2]\n",
      " [2 3 1]\n",
      " [2 4 2]\n",
      " [4 3 0]]\n",
      "[MAIN]\t Propensities:\n",
      "[[0.6093588  0.47257691 0.73821055]\n",
      " [0.72471802 0.01251511 0.02651197]\n",
      " [0.20570593 0.28579651 0.72016379]\n",
      " [0.73454479 0.7598084  0.03725246]\n",
      " [0.28193402 0.40183564 0.11712763]]\n",
      "[MAIN]\t Inverse Propensities:\n",
      "[[ 1.64106926  2.11605767  1.35462708]\n",
      " [ 1.37984703 79.90340363 37.71880959]\n",
      " [ 4.86130867  3.49899306  1.38857302]\n",
      " [ 1.36138738  1.31612127 26.84386663]\n",
      " [ 3.54692917  2.48857964  8.53769503]]\n",
      "[MAIN]\t Observations:\n",
      "[[ True False  True]\n",
      " [ True False False]\n",
      " [False  True  True]\n",
      " [ True False False]\n",
      " [False  True False]]\n",
      "[MAIN]\t MSE: Vanilla, SN, UN, IN:\n",
      "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 7\n",
      "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  13.113076456208551 (=? NumUsers * NumItems) 15\n",
      "Metrics.ITEMWISE_METRICS: [LOG]\t Vanilla, SelfNormalized, UserNormalized, ItemNormalized 3.9965611787265005 4.571651654826901 3.693243874912445 4.227078688800476\n",
      "[MAIN]\t MAE: Vanilla, SN, UN, IN:\n",
      "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 7\n",
      "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  13.113076456208551 (=? NumUsers * NumItems) 15\n",
      "Metrics.ITEMWISE_METRICS: [LOG]\t Vanilla, SelfNormalized, UserNormalized, ItemNormalized 1.5759397041848615 1.8027116399203709 1.595920521374922 1.7702536983306765\n",
      "[MAIN]\t DCG: Vanilla, SN, UN, IN:\n",
      "Jitter.init: [DBG]\t (NumUsers, NumItems)\n",
      "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 7\n",
      "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  13.113076456208551 (=? NumUsers * NumItems) 15\n",
      "Metrics.DCG: [LOG]\t DCG, SN-DCG, UN-DCG, IN-DCG\n",
      "[MAIN]\t CG: Vanilla, SN, UN, IN:\n",
      "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 7\n",
      "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  13.113076456208551 (=? NumUsers * NumItems) 15\n",
      "Metrics.CG: [LOG]\t CG, SN-CG, UN-CG, IN-CG\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    shape = (5,3)\n",
    "    a = numpy.random.randint(0,5, size=shape) # True ratings\n",
    "    b = numpy.random.randint(0,5, size=shape) #Predicted ratings\n",
    "    \n",
    "    print (\"[MAIN]\\t True ratings:\")\n",
    "    print (a)\n",
    "    print (\"[MAIN]\\t Predicted ratings:\")\n",
    "    print (b)\n",
    "    \n",
    "    inversePropensities = numpy.random.random(shape)\n",
    "    print (\"[MAIN]\\t Propensities:\")\n",
    "    print (inversePropensities)\n",
    "    obs = numpy.random.random(shape)\n",
    "    obs = obs < inversePropensities # Mask O(u,i)\n",
    "    inversePropensities = numpy.reciprocal(inversePropensities)\n",
    "    print (\"[MAIN]\\t Inverse Propensities:\")\n",
    "    print (inversePropensities)\n",
    "\n",
    "    print (\"[MAIN]\\t Observations:\")\n",
    "    print (obs)\n",
    "    \n",
    "    observed_a = numpy.ma.array(a, dtype = numpy.longdouble, copy = True, \n",
    "                            mask = numpy.logical_not(obs), fill_value = 0, hard_mask = True)\n",
    "    # True rating masking只取O(u,i)中 = 1 的数据\n",
    "     \n",
    "    print (\"[MAIN]\\t MSE: Vanilla, SN, UN, IN:\"),\n",
    "    MSE(observed_a, b, inversePropensities, verbose = True)\n",
    "    print (\"[MAIN]\\t MAE: Vanilla, SN, UN, IN:\")\n",
    "    MAE(observed_a, b, inversePropensities, verbose = True)\n",
    "    print (\"[MAIN]\\t DCG: Vanilla, SN, UN, IN:\")\n",
    "    DCG(observed_a, b, inversePropensities, cut_off = 50, verbose = True)\n",
    "    \n",
    "    print (\"[MAIN]\\t CG: Vanilla, SN, UN, IN:\")\n",
    "    CG(observed_a, b, inversePropensities, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a882d8",
   "metadata": {},
   "source": [
    "## MF 矩阵分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47cff22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import scipy.optimize\n",
    "# import sys\n",
    "# import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c786c1b3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def PREDICTED_SCORES(user_vectors, item_vectors, user_biases, item_biases, global_bias, use_bias = True):\n",
    "    rawScores = numpy.dot(user_vectors, item_vectors.T)\n",
    "    if use_bias:\n",
    "        biasedScores = rawScores + user_biases[:,None] + item_biases[None,:] + global_bias\n",
    "        return biasedScores\n",
    "    else:\n",
    "        return rawScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47fca099",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def GENERATE_MATRIX(observed_ratings, inverse_propensities, l2_regularization, num_dimensions, normalization,\n",
    "        bias_mode = 'Regularized', mode = 'MSE', start_vec = None, verbose = False):\n",
    "\n",
    "    metricMode = None\n",
    "    if mode == 'MSE':\n",
    "        metricMode = 1\n",
    "    elif mode == 'MAE':\n",
    "        metricMode = 2\n",
    "    else:\n",
    "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Metric not supported:\", mode)\n",
    "        sys.exit(0)\n",
    "\n",
    "#     inversePropensities = Metrics.SET_PROPENSITIES(observed_ratings, inverse_propensities, False)\n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, False)\n",
    "\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "    numObservations = numpy.ma.count(observed_ratings)\n",
    "\n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perItemNormalizer = numpy.ma.sum(inversePropensities, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemNormalizer = numpy.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
    "\n",
    "    globalNormalizer = numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "\n",
    "    normalizedPropensities = None\n",
    "    if normalization == 'Vanilla':\n",
    "        normalizedPropensities = inversePropensities\n",
    "    elif normalization == 'SelfNormalized':\n",
    "        normalizedPropensities = scale * numpy.ma.divide(inversePropensities, globalNormalizer)\n",
    "    elif normalization == 'UserNormalized':\n",
    "        normalizedPropensities = numItems * numpy.ma.divide(inversePropensities, perUserNormalizer[:, None])\n",
    "    elif normalization == 'ItemNormalized':\n",
    "        normalizedPropensities = numUsers * numpy.ma.divide(inversePropensities, perItemNormalizer[None, :])\n",
    "    else:\n",
    "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Normalization not supported:\", normalization)\n",
    "        sys.exit(0)\n",
    "    \n",
    "    useBias = None\n",
    "    regularizeBias = None\n",
    "    if bias_mode == 'None':\n",
    "        useBias = False\n",
    "        regularizeBias = False\n",
    "    elif bias_mode == 'Regularized':\n",
    "        useBias = True\n",
    "        regularizeBias = True\n",
    "    elif bias_mode == 'Free':\n",
    "        useBias = True\n",
    "        regularizeBias = False\n",
    "    else:\n",
    "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Bias mode not supported:\", bias_mode)\n",
    "        sys.exit(0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"MF.GENERATE_MATRIX: [LOG]\\t Lamda:\", l2_regularization, \"\\t NumDims:\", num_dimensions,\\\n",
    "            \"\\t Normalization:\", normalization, \"\\t Metric:\", mode, \"\\t BiasMode:\", bias_mode)\n",
    "\n",
    "    normalizedPropensities = numpy.ma.filled(normalizedPropensities, 0.0)\n",
    "    observedRatings = numpy.ma.filled(observed_ratings, 0)\n",
    "    \n",
    "    def Mat2Vec(user_vectors, item_vectors, user_biases, item_biases, global_bias):\n",
    "        allUserParams = numpy.concatenate((user_vectors, user_biases[:,None]), axis = 1)\n",
    "        allItemParams = numpy.concatenate((item_vectors, item_biases[:,None]), axis = 1)\n",
    "        \n",
    "        allParams = numpy.concatenate((allUserParams, allItemParams), axis = 0)\n",
    "        paramVector = numpy.reshape(allParams, (numUsers + numItems)*(num_dimensions + 1))\n",
    "        paramVector = numpy.concatenate((paramVector, [global_bias]))\n",
    "        return paramVector.astype(numpy.float)\n",
    "        \n",
    "    def Vec2Mat(paramVector):\n",
    "        globalBias = paramVector[-1]\n",
    "        remainingParams = paramVector[:-1]\n",
    "        allParams = numpy.reshape(remainingParams, (numUsers + numItems, num_dimensions + 1))\n",
    "        allUserParams = allParams[0:numUsers,:]\n",
    "        allItemParams = allParams[numUsers:, :]\n",
    "        \n",
    "        userVectors = (allUserParams[:,0:-1]).astype(numpy.longdouble)\n",
    "        userBiases = (allUserParams[:,-1]).astype(numpy.longdouble)\n",
    "        \n",
    "        itemVectors = (allItemParams[:,0:-1]).astype(numpy.longdouble)\n",
    "        itemBiases = (allItemParams[:,-1]).astype(numpy.longdouble)\n",
    "        return userVectors, itemVectors, userBiases, itemBiases, globalBias\n",
    "    \n",
    "    def Objective(paramVector):\n",
    "        userVectors, itemVectors, userBiases, itemBiases, globalBias = Vec2Mat(paramVector)\n",
    "        biasedScores = PREDICTED_SCORES(userVectors, itemVectors, userBiases, itemBiases, globalBias, useBias)\n",
    "\n",
    "        delta = numpy.subtract(biasedScores, observedRatings)\n",
    "        loss = None\n",
    "        if metricMode == 1:\n",
    "            loss = numpy.square(delta)\n",
    "        elif metricMode == 2:\n",
    "            loss = numpy.abs(delta)\n",
    "        else:\n",
    "            sys.exit(0)\n",
    "\n",
    "        weightedLoss = numpy.multiply(loss, normalizedPropensities)\n",
    "        objective = numpy.sum(weightedLoss, dtype = numpy.longdouble)\n",
    "\n",
    "        gradientMultiplier = None\n",
    "        if metricMode == 1:\n",
    "            gradientMultiplier = numpy.multiply(normalizedPropensities, 2 * delta)\n",
    "        elif metricMode == 2:\n",
    "            gradientMultiplier = numpy.zeros(numpy.shape(delta), dtype = numpy.int)\n",
    "            gradientMultiplier[delta > 0] = 1\n",
    "            gradientMultiplier[delta < 0] = -1\n",
    "            gradientMultiplier = numpy.multiply(normalizedPropensities, gradientMultiplier)\n",
    "        else:\n",
    "            sys.exit(0)\n",
    "\n",
    "        userVGradient = numpy.dot(gradientMultiplier, itemVectors)\n",
    "        itemVGradient = numpy.dot(gradientMultiplier.T, userVectors)\n",
    "\n",
    "        userBGradient = None\n",
    "        itemBGradient = None\n",
    "        globalBGradient = None\n",
    "        if useBias:\n",
    "            userBGradient = numpy.sum(gradientMultiplier, axis = 1, dtype = numpy.longdouble)\n",
    "            itemBGradient = numpy.sum(gradientMultiplier, axis = 0, dtype = numpy.longdouble)\n",
    "            globalBGradient = numpy.sum(gradientMultiplier, dtype = numpy.longdouble)\n",
    "        else:\n",
    "            userBGradient = numpy.zeros(numpy.shape(userBiases), dtype = numpy.longdouble)\n",
    "            itemBGradient = numpy.zeros(numpy.shape(itemBiases), dtype = numpy.longdouble)\n",
    "            globalBGradient = 0.0\n",
    "\n",
    "        if l2_regularization > 0:\n",
    "            scaledPenalty = 1.0 * l2_regularization * scale / (numUsers + numItems)\n",
    "            if regularizeBias:\n",
    "                scaledPenalty /= (num_dimensions + 1)\n",
    "            else:\n",
    "                scaledPenalty /= num_dimensions\n",
    "\n",
    "            userVGradient += 2 * scaledPenalty * userVectors\n",
    "            itemVGradient += 2 * scaledPenalty * itemVectors\n",
    "          \n",
    "            objective += scaledPenalty * numpy.sum(numpy.square(userVectors), dtype = numpy.longdouble)\n",
    "            objective += scaledPenalty * numpy.sum(numpy.square(itemVectors), dtype = numpy.longdouble)\n",
    " \n",
    "            if regularizeBias:\n",
    "                userBGradient += 2 * scaledPenalty * userBiases\n",
    "                itemBGradient += 2 * scaledPenalty * itemBiases\n",
    "                globalBGradient += 2 * scaledPenalty * globalBias\n",
    "                objective += scaledPenalty * numpy.sum(numpy.square(userBiases), dtype = numpy.longdouble)\n",
    "                objective += scaledPenalty * numpy.sum(numpy.square(itemBiases), dtype = numpy.longdouble)\n",
    "                objective += scaledPenalty * globalBias * globalBias\n",
    "            \n",
    "        gradient = Mat2Vec(userVGradient, itemVGradient, userBGradient, itemBGradient, globalBGradient)\n",
    "\n",
    "        if verbose:\n",
    "            print( \".\",)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        return objective, gradient\n",
    "    \n",
    "    def ObjectiveOnly(paramVector):\n",
    "        objective, gradient = Objective(paramVector)\n",
    "        return objective\n",
    "    def GradientOnly(paramVector):\n",
    "        objective, gradient = Objective(paramVector)\n",
    "        return gradient\n",
    "    \n",
    "    userVectorsInit = None\n",
    "    itemVectorsInit = None\n",
    "    userBiasesInit = None\n",
    "    itemBiasesInit = None\n",
    "    globalBiasInit = None\n",
    "    if start_vec is None:\n",
    "        userVectorsInit = numpy.random.standard_normal((numUsers, num_dimensions))\n",
    "        itemVectorsInit = numpy.random.standard_normal((numItems, num_dimensions))\n",
    "        userBiasesInit = numpy.zeros(numUsers, dtype = numpy.float)\n",
    "        itemBiasesInit = numpy.zeros(numItems, dtype = numpy.float)\n",
    "        globalBiasInit = 0\n",
    "    else:\n",
    "        userVectorsInit = start_vec[0]\n",
    "        itemVectorsInit = start_vec[1]\n",
    "        userBiasesInit = start_vec[2]\n",
    "        itemBiasesInit = start_vec[3]\n",
    "        globalBiasInit = start_vec[4]\n",
    "    \n",
    "    startVector = Mat2Vec(userVectorsInit, itemVectorsInit, userBiasesInit, itemBiasesInit, globalBiasInit)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"MF.GENERATE_MATRIX: [DBG]\\t Checking gradients\")\n",
    "        print(scipy.optimize.check_grad(ObjectiveOnly, GradientOnly, startVector))\n",
    "\n",
    "    ops = {'maxiter': 2000, 'disp': False, 'gtol': 1e-5,\\\n",
    "            'ftol': 1e-5, 'maxcor': 50}\n",
    "\n",
    "    result = scipy.optimize.minimize(fun = Objective, x0 = startVector,\n",
    "                    method = 'L-BFGS-B', jac = True, tol = 1e-5, options = ops)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        print(\"MF.GENERATE_MATRIX: [DBG]\\t Optimization result:\", result['message'])\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return Vec2Mat(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40b45200",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAIN]\t Partially observed ratings matrix\n",
      "[[5 -- --]\n",
      " [-- -- 2]\n",
      " [1 -- --]\n",
      " [5 4 --]\n",
      " [4 3 --]]\n",
      "MF.GENERATE_MATRIX: [LOG]\t Lamda: 1.0 \t NumDims: 5 \t Normalization: Vanilla \t Metric: MSE \t BiasMode: Regularized\n",
      "MF.GENERATE_MATRIX: [DBG]\t Checking gradients\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "1.2005834188347902e-05\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "MF.GENERATE_MATRIX: [DBG]\t Optimization result: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "MF.GENERATE_MATRIX: [LOG]\t Lamda: 1.0 \t NumDims: 5 \t Normalization: Vanilla \t Metric: MSE \t BiasMode: Regularized\n",
      "MF.GENERATE_MATRIX: [DBG]\t Checking gradients\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "2.1979538262588914e-05\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "MF.GENERATE_MATRIX: [DBG]\t Optimization result: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "MF.GENERATE_MATRIX: [LOG]\t Lamda: 1.0 \t NumDims: 5 \t Normalization: Vanilla \t Metric: MAE \t BiasMode: Regularized\n",
      "MF.GENERATE_MATRIX: [DBG]\t Checking gradients\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\AppData\\Local\\Temp/ipykernel_20764/1252471770.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  checkY = scipy.sparse.coo_matrix((vals, (rows,cols)), dtype = numpy.int)\n",
      "C:\\Users\\Tim\\AppData\\Local\\Temp/ipykernel_20764/1252471770.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  checkY = numpy.ma.array(checkY, dtype = numpy.int, mask = checkY <= 0, hard_mask = True, copy = False)\n",
      "C:\\Users\\Tim\\AppData\\Local\\Temp/ipykernel_20764/1589588316.py:172: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  userBiasesInit = numpy.zeros(numUsers, dtype = numpy.float)\n",
      "C:\\Users\\Tim\\AppData\\Local\\Temp/ipykernel_20764/1589588316.py:173: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  itemBiasesInit = numpy.zeros(numItems, dtype = numpy.float)\n",
      "C:\\Users\\Tim\\AppData\\Local\\Temp/ipykernel_20764/1589588316.py:70: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return paramVector.astype(numpy.float)\n",
      "C:\\Users\\Tim\\AppData\\Local\\Temp/ipykernel_20764/1589588316.py:106: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  gradientMultiplier = numpy.zeros(numpy.shape(delta), dtype = numpy.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "1.0355460500990855e-05\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "MF.GENERATE_MATRIX: [DBG]\t Optimization result: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "MF.GENERATE_MATRIX: [LOG]\t Lamda: 1.0 \t NumDims: 5 \t Normalization: SelfNormalized \t Metric: MSE \t BiasMode: Regularized\n",
      "MF.GENERATE_MATRIX: [DBG]\t Checking gradients\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "8.356802052882406e-06\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "MF.GENERATE_MATRIX: [DBG]\t Optimization result: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "MF.GENERATE_MATRIX: [LOG]\t Lamda: 1.0 \t NumDims: 5 \t Normalization: Vanilla \t Metric: MSE \t BiasMode: Free\n",
      "MF.GENERATE_MATRIX: [DBG]\t Checking gradients\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "1.1521236091899486e-05\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "MF.GENERATE_MATRIX: [DBG]\t Optimization result: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "MF.GENERATE_MATRIX: [LOG]\t Lamda: 1.0 \t NumDims: 5 \t Normalization: SelfNormalized \t Metric: MSE \t BiasMode: None\n",
      "MF.GENERATE_MATRIX: [DBG]\t Checking gradients\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "1.699598295979351e-05\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "MF.GENERATE_MATRIX: [DBG]\t Optimization result: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "[MAIN]\t User vectors\n",
      "[[ 1.17095783  0.76120386 -0.53276839  0.67221519 -0.97204572]\n",
      " [ 0.53748609 -0.3884386  -0.42840798 -0.48108207 -0.56795039]\n",
      " [ 0.241728    0.15457046 -0.10854251  0.13807214 -0.19854826]\n",
      " [ 1.22253918  0.79423773 -0.55920512  0.69031823 -1.00281886]\n",
      " [ 0.94445676  0.60998767 -0.4344714   0.53494972 -0.77634052]]\n",
      "[MAIN]\t Item vectors\n",
      "[[ 1.5424114   1.00263085 -0.70764864  0.88329573 -1.27739863]\n",
      " [ 1.19731261  0.77533162 -0.54726452  0.67591178 -0.98204951]\n",
      " [ 0.53727361 -0.38885011 -0.42832572 -0.48078845 -0.56818514]]\n",
      "[MAIN]\t User biases\n",
      "[0. 0. 0. 0. 0.]\n",
      "[MAIN]\t Item biases\n",
      "[0. 0. 0.]\n",
      "[MAIN]\t Global bias\n",
      "0.0\n",
      "[MAIN]\t Predicted scores\n",
      "[[4.78177268 3.69270842 0.79043757]\n",
      " [1.04328779 0.809409   1.17731932]\n",
      " [0.98021489 0.75697761 0.16268957]\n",
      " [4.96846095 3.83700432 0.82541028]\n",
      " [3.84000155 2.96550715 0.64024069]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import scipy.sparse\n",
    "    \n",
    "    rows = [2,1,4,3,0,4,3]\n",
    "    cols = [0,2,1,1,0,0,0]\n",
    "    vals = [1,2,3,4,5,4,5]\n",
    "    checkY = scipy.sparse.coo_matrix((vals, (rows,cols)), dtype = numpy.int)\n",
    "    checkY = checkY.toarray()\n",
    "    checkY = numpy.ma.array(checkY, dtype = numpy.int, mask = checkY <= 0, hard_mask = True, copy = False)\n",
    "    print(\"[MAIN]\\t Partially observed ratings matrix\")\n",
    "    print(checkY)\n",
    "\n",
    "    randomPropensities = numpy.random.random(size = numpy.shape(checkY))\n",
    "    randomInvPropensities = numpy.reciprocal(randomPropensities)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, None, 1.0, 5, 'Vanilla',\n",
    "                                                'Regularized', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'Vanilla',\n",
    "                                                'Regularized', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'Vanilla',\n",
    "                                                'Regularized', 'MAE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'SelfNormalized',\n",
    "                                                'Regularized', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, None, 1.0, 5, 'Vanilla',\n",
    "                                                'Free', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'SelfNormalized',\n",
    "                                                'None', 'MSE', None, verbose = True)\n",
    "\n",
    "\n",
    "    print(\"[MAIN]\\t User vectors\")\n",
    "    print(userVectors)\n",
    "    print(\"[MAIN]\\t Item vectors\")\n",
    "    print(itemVectors)\n",
    "    print(\"[MAIN]\\t User biases\")\n",
    "    print(userBiases)\n",
    "    print(\"[MAIN]\\t Item biases\")\n",
    "    print(itemBiases)\n",
    "    print(\"[MAIN]\\t Global bias\")\n",
    "    print(globalBias)\n",
    "    \n",
    "    completeScores = PREDICTED_SCORES(userVectors, itemVectors, userBiases, itemBiases, globalBias, True)\n",
    "    print(\"[MAIN]\\t Predicted scores\")\n",
    "    print(completeScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480f2e8",
   "metadata": {},
   "source": [
    "## Expt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efb2d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MF\n",
    "# import numpy\n",
    "import scipy.sparse.linalg\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e5282a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def MF_TRAIN(params, train_observations, inv_propensities, normalization, metric, start_vector):\n",
    "    retVal = None\n",
    "    actualStart = None\n",
    "    if start_vector is not None:\n",
    "        actualStart = (start_vector[0][:,0:params[1]], start_vector[1][:,0:params[1]],\n",
    "                        start_vector[2], start_vector[3], start_vector[4])\n",
    "\n",
    "    tempInvPropensities = None\n",
    "    if inv_propensities is not None:\n",
    "        tempInvPropensities = (4.0 / 3.0) * inv_propensities\n",
    "        if params[2] >= 0:\n",
    "            tempInvPropensities = numpy.clip(tempInvPropensities, a_min = 0, a_max = params[2])\n",
    "\n",
    "    retVal = MF.GENERATE_MATRIX(train_observations, tempInvPropensities, params[0], \n",
    "                                params[1], normalization, bias_mode = params[3], mode = metric, \n",
    "                                start_vec = actualStart, verbose = False)\n",
    "\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4801a7fe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def FINAL_TRAIN(approach_tuple, metric, observations, start_vector):\n",
    "    invP = approach_tuple[1]\n",
    "    normN = approach_tuple[2]\n",
    "    bestLambda = approach_tuple[3][0]\n",
    "    bestDims = approach_tuple[3][1]\n",
    "    bestClip = approach_tuple[3][2]\n",
    "    bestBias = approach_tuple[3][3]\n",
    "    actualStart = None\n",
    "    if start_vector is not None:\n",
    "        actualStart = (start_vector[0][:,0:bestDims], start_vector[1][:,0:bestDims],\n",
    "                        start_vector[2], start_vector[3], start_vector[4])\n",
    "\n",
    "    tempInvP = None\n",
    "    if bestClip < 0 or invP is None:\n",
    "        tempInvP = invP\n",
    "    else:\n",
    "        tempInvP = numpy.clip(invP, a_min = 0, a_max = bestClip)\n",
    "\n",
    "    retVal = MF.GENERATE_MATRIX(observations, tempInvP, bestLambda, bestDims, normN, bias_mode = bestBias,\n",
    "                        mode = metric, start_vec = actualStart)\n",
    "\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6abc3a99",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def INIT_PARAMS(partial_observations, num_dimensions):\n",
    "    averageObservedRating = numpy.ma.mean(partial_observations, dtype = numpy.longdouble)\n",
    "    completeRatings = numpy.ma.filled(partial_observations.astype(numpy.float), averageObservedRating)\n",
    "    numUsers, numItems = numpy.shape(partial_observations)\n",
    "\n",
    "    u,s,vt = scipy.sparse.linalg.svds(completeRatings, k = num_dimensions, ncv = 50, tol = 1e-7, which = 'LM', \n",
    "                        v0 = None, maxiter = 2000, return_singular_vectors = True)\n",
    "            \n",
    "    startTuple = (u, numpy.transpose(numpy.multiply(vt, s[:,None])), \n",
    "                     numpy.zeros(numUsers, dtype = numpy.longdouble), \n",
    "                     numpy.zeros(numItems, dtype = numpy.longdouble), \n",
    "                     averageObservedRating)\n",
    "    return startTuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9753b08",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def TRAIN_HELPER(approach, gold_inv_propensities, nb_inv_propensities):\n",
    "    invP = None\n",
    "    if approach == 'Naive':\n",
    "        invP = None\n",
    "    elif approach.startswith('Gold'):\n",
    "        invP = gold_inv_propensities\n",
    "    elif approach.startswith('NB'):\n",
    "        invP = nb_inv_propensities\n",
    "    else:\n",
    "        print (\"TRAIN_HELPER: [ERR] Unrecognized approach\", approach)\n",
    "        sys.exit(0)\n",
    "\n",
    "    normN = None\n",
    "    if approach == 'Naive' or approach.endswith('-IPS'):\n",
    "        normN = 'Vanilla'\n",
    "    elif approach.endswith('-SNIPS'):\n",
    "        normN = 'SelfNormalized'\n",
    "    elif approach.endswith('-UNIPS'):\n",
    "        normN = 'UserNormalized'\n",
    "    elif approach.endswith('-INIPS'):\n",
    "        normN = 'ItemNormalized'\n",
    "    else:\n",
    "        print (\"TRAIN_HELPER: [ERR] Unrecognized approach\", approach)\n",
    "        sys.exit(0)\n",
    "        \n",
    "    return invP, normN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa7931",
   "metadata": {},
   "source": [
    "以下代码并不能运行，应该是实验二的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3639ae18",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5896/968111578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#     args = parser.parse_args()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mapproaches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "%%script false #去掉以运行\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "#     import Datasets\n",
    "# Datasets 已经合并在lenskit下\n",
    "    from lenskit.datasets import ML100K\n",
    "#     import Metrics\n",
    "#     import Propensity\n",
    "    import pickle\n",
    "    import os\n",
    "    import itertools\n",
    "    from joblib import Parallel, delayed\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Semi-Synthetic Learning on ML100K.')\n",
    "    parser.add_argument('--seed', '-s', metavar='S', type=int, \n",
    "                        help='Seed for numpy.random', default=387)\n",
    "    parser.add_argument('--trial', '-t', metavar='T', type=int, \n",
    "                        help='Trial ID', default=1)\n",
    "    parser.add_argument('--alphas', '-a', metavar='A', type=str, \n",
    "                        help='Alpha values', default='1,0.5,0.25,0.125,0.0625,0.03125')\n",
    "    parser.add_argument('--lambdas', '-l', metavar='L', type=str, \n",
    "                        help='Lambda values', default='0.008,0.04,0.2,1,5,25,125')\n",
    "    parser.add_argument('--numdims', '-n', metavar='N', type=str, \n",
    "                        help='Dimension values', default='20')\n",
    "    parser.add_argument('--clips', '-c', metavar='C', type=str, \n",
    "                        help='Clip values', default='-1')\n",
    "    parser.add_argument('--estimators', '-e', metavar='E', type=str, \n",
    "                        help='Learning methods', default='Naive,Gold-IPS,Gold-SNIPS')\n",
    "    parser.add_argument('--metric', '-m', metavar='M', type=str, \n",
    "                        help='Metrics', default='MSE')\n",
    "    \n",
    "    # 此处有bug，在Train中有类似的bug\n",
    "#     args = parser.parse_args()\n",
    "    numpy.random.seed(args.seed)\n",
    "    \n",
    "    approaches = args.estimators.strip().split(',')\n",
    "    \n",
    "    approachDict = {}\n",
    "    for approach in approaches:\n",
    "        approachDict[(approach, args.metric)] = len(approachDict)\n",
    "        \n",
    "    alphas = []\n",
    "    tokens = args.alphas.strip().split(',')\n",
    "    for token in tokens:\n",
    "        alphas.append(float(token))\n",
    "    \n",
    "    lambdas = []\n",
    "    tokens = args.lambdas.strip().split(',')\n",
    "    for token in tokens:\n",
    "        lambdas.append(float(token))\n",
    "        \n",
    "    numDims = []\n",
    "    tokens = args.numdims.strip().split(',')\n",
    "    for token in tokens:\n",
    "        numDims.append(int(token))\n",
    "    \n",
    "    clipVals = []\n",
    "    tokens = args.clips.strip().split(',')\n",
    "    for token in tokens:\n",
    "        clipVals.append(int(token))\n",
    "\n",
    "    numAlphas = len(alphas)\n",
    "    numApproaches = len(approachDict)\n",
    "    \n",
    "    biasModes = ['Free']\n",
    "    numDimSettings = len(numDims)\n",
    "    numClipSettings = len(clipVals)\n",
    "    numBiasModes = len(biasModes)\n",
    " \n",
    "    numLambdas = len(lambdas)\n",
    "    numParamSettings = numLambdas * numDimSettings * numClipSettings * numBiasModes\n",
    "    \n",
    "    paramSettings = list(itertools.product(lambdas, numDims, clipVals, biasModes))\n",
    "       \n",
    "#     ML100KCompleteTest = Datasets.ML100K('../')\n",
    "    ML100KCompleteTest = ML100K('../')\n",
    "    \n",
    "    allEstimates = numpy.zeros((numApproaches, numAlphas), dtype = numpy.longdouble)\n",
    "    \n",
    "    currMetric = None\n",
    "    if args.metric == 'MSE':\n",
    "        currMetric = Metrics.MSE\n",
    "    elif args.metric == 'MAE':\n",
    "        currMetric = Metrics.MAE\n",
    "    else:\n",
    "        print(\"Expt2: [ERR] Unrecognized metric\", args.metric)\n",
    "        sys.exit(0)\n",
    "        \n",
    "    print (\"Expt2: [LOG] Starting metric\", args.metric)\n",
    "        \n",
    "    def updateResults(val, approach, ind):\n",
    "        approachTuple = (approach, args.metric)\n",
    "        approachIndex = approachDict[approachTuple]\n",
    "        allEstimates[approachIndex, ind] = val\n",
    "            \n",
    "    print (\"Expt2: [LOG] Trial\", args.trial)\n",
    "    numpy.random.seed(args.seed + args.trial)\n",
    "    \n",
    "#     此处需要修改outputfile路径， 会以pkl形式保存模型\n",
    "#     outputFile = '../logs/expt2/'+str(args.seed)+'_'+str(args.trial)+'_'+args.metric+'_'\n",
    "    \n",
    "    for ind, alpha in enumerate(alphas):\n",
    "        print (\"Expt2: [LOG] Alpha:\", alpha)\n",
    "            \n",
    "#         暂时还未找到关于 Propensity module的信息，sklearn里面好像有类似的包，但不知道用法\n",
    "#         partialObservations, goldPropensities = Propensity.PARTIAL_OBSERVE(ML100KCompleteTest, alpha, 0.05, verbose = False)\n",
    "       \n",
    "        flatObservations = numpy.ma.compressed(partialObservations) \n",
    "        observedHistogram = numpy.bincount(flatObservations, minlength = 6)[1:]\n",
    "        observedHistogram = observedHistogram.astype(numpy.longdouble) / \\\n",
    "                                observedHistogram.sum(dtype = numpy.longdouble)\n",
    "        print (\"Expt2: [LOG] Observed Marginals: \", observedHistogram)\n",
    "       \n",
    "        goldInvPropensities = numpy.reciprocal(goldPropensities)\n",
    "        \n",
    "        foldScores = numpy.zeros((numApproaches, 4, numParamSettings), dtype = numpy.longdouble)\n",
    "        foldTestScores = numpy.zeros((numApproaches, 4, numParamSettings), dtype = numpy.longdouble)\n",
    "        \n",
    "        observationIndices = numpy.ma.nonzero(partialObservations)\n",
    "        numObservations = numpy.ma.count(partialObservations)\n",
    " \n",
    "        shuffleIndices = numpy.random.permutation(numObservations)\n",
    "        fractionObservations = int(numObservations/4)\n",
    "        firstFold = shuffleIndices[:fractionObservations]\n",
    "        secondFold = shuffleIndices[fractionObservations:2*fractionObservations]\n",
    "        thirdFold = shuffleIndices[2*fractionObservations:3*fractionObservations]\n",
    "        fourthFold = shuffleIndices[3*fractionObservations:]\n",
    "        print (\"Expt2: [LOG] Split %d observations into folds. Fold sizes:\" % len(shuffleIndices),\\\n",
    "                        len(firstFold), len(secondFold), len(thirdFold), len(fourthFold))\n",
    "        \n",
    "        for fold in xrange(4):\n",
    "            print (\"Expt2: [LOG] Fold:\", fold)\n",
    "            trainObservations = numpy.ma.copy(partialObservations)\n",
    "            testObservations = numpy.ma.copy(partialObservations)\n",
    "\n",
    "            if fold == 0:\n",
    "                trainObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            elif fold == 1:\n",
    "                trainObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            elif fold == 2:\n",
    "                trainObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            elif fold == 3:\n",
    "                trainObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            else:\n",
    "                print (\"Expt2: [ERR] #Folds not supported \", fold)\n",
    "                sys.exit(0)\n",
    "                   \n",
    "            #Get starting params by SVD\n",
    "            startFileName = outputFile + 'fold' + str(fold) + '_' + str(alpha) +'_init.pkl'\n",
    "            startTuple = None\n",
    "            if os.path.exists(startFileName):\n",
    "                g = open(startFileName, 'rb')\n",
    "                startTuple = pickle.load(g)\n",
    "                g.close()\n",
    "            else:\n",
    "                startTuple = INIT_PARAMS(trainObservations, 20)\n",
    "                g = open(startFileName, 'wb')\n",
    "                pickle.dump(startTuple, g, -1)\n",
    "                g.close()\n",
    "            \n",
    "            for approach in approaches:\n",
    "                print (\"Starting approach \", approach)\n",
    "                invP, normN = TRAIN_HELPER(approach, goldInvPropensities, None)\n",
    "                approachTuple = (approach, args.metric)\n",
    "                approachIndex = approachDict[approachTuple]\n",
    "                modelFileName = outputFile + 'fold' + str(fold) + '_' + str(alpha) +'_'+approach+'.pkl'\n",
    "                modelsPerLambda = None\n",
    "                if os.path.exists(modelFileName):\n",
    "                    g = open(modelFileName, 'rb')\n",
    "                    modelsPerLambda = pickle.load(g)\n",
    "                    g.close()\n",
    "                    print (\"Expt2: [LOG]\\t Loaded trained models for each lambda from \", modelFileName)\n",
    "                else:\n",
    "                    modelsPerLambda = Parallel(n_jobs = -1, verbose = 0)(delayed(MF_TRAIN)(l2Lambda, \n",
    "                                            trainObservations, invP, normN, args.metric, startTuple)\n",
    "                                            for l2Lambda in paramSettings)\n",
    "                    g = open(modelFileName, 'wb')\n",
    "                    pickle.dump(modelsPerLambda, g, -1)\n",
    "                    g.close()\n",
    "                    print (\"Expt2: [LOG]\\t Saved trained models for each lambda to \", modelFileName)\n",
    "\n",
    "                for lambdaIndex, eachModel in enumerate(modelsPerLambda):\n",
    "                    selectedBiasMode = paramSettings[lambdaIndex][3]\n",
    "                    selectedBias = True\n",
    "                    if selectedBiasMode == 'None':\n",
    "                        selectedBias = False\n",
    "\n",
    "                    predictedY = MF.PREDICTED_SCORES(eachModel[0], eachModel[1], \n",
    "                                                eachModel[2], eachModel[3], eachModel[4], use_bias = selectedBias)\n",
    "                    score = None\n",
    "                    if invP is not None:\n",
    "                        score = currMetric(testObservations, predictedY, 4.0*invP)\n",
    "                    else:\n",
    "                        score = currMetric(testObservations, predictedY, None)\n",
    "                        \n",
    "                    if normN == 'Vanilla':\n",
    "                        score = score[0]\n",
    "                    elif normN == 'SelfNormalized':\n",
    "                        score = score[1]\n",
    "                    elif normN == 'UserNormalized':\n",
    "                        score = score[2]\n",
    "                    elif normN == 'ItemNormalized':\n",
    "                        score = score[3]\n",
    "                    else:\n",
    "                        print (\"Expt2: [ERR] Normalization not supported for metric \", normN, args.metric)\n",
    "                        sys.exit(0)\n",
    "                    \n",
    "                    foldScores[approachIndex, fold, lambdaIndex] = score\n",
    "                    \n",
    "                    foldTestScore = currMetric(ML100KCompleteTest, predictedY, None)[0]\n",
    "                    foldTestScores[approachIndex, fold, lambdaIndex] = foldTestScore\n",
    "                    print (\"Expt2: [LOG] Lambda/NumDims: \", paramSettings[lambdaIndex],\n",
    "                                \"\\t Test Fold Score: \", score, \"\\t Test Set Score: \", foldTestScore)\n",
    "                \n",
    "                #Save foldScores and foldTestScores after each approach in each fold. Overwrite if needed.\n",
    "                scoresFile = outputFile + 'Alpha'+ str(alpha)+'_foldScores.pkl'\n",
    "                scoresData = (foldScores, foldTestScores)\n",
    "                g = open(scoresFile, 'wb')\n",
    "                pickle.dump(scoresData, g, -1)\n",
    "                g.close()\n",
    "                sys.stdout.flush()        \n",
    "        \n",
    "        eventualApproachParams = []\n",
    "        for approach in approaches:\n",
    "            invP, normN = TRAIN_HELPER(approach, goldInvPropensities, None)\n",
    "            approachTuple = (approach, args.metric)\n",
    "            approachIndex = approachDict[approachTuple]\n",
    "            approachScores = foldScores[approachIndex,:,:]\n",
    "            allFoldScores = approachScores.sum(axis = 0, dtype = numpy.longdouble)\n",
    "            bestLambdaIndex = numpy.argmin(allFoldScores)\n",
    "            bestLambda = paramSettings[bestLambdaIndex]\n",
    "            print (\"FINAL_TRAIN: [LOG] Retraining \", approach, \" Best lambda/numDims\", bestLambda    )\n",
    "            for everyLambdaIndex, everyLambda in enumerate(paramSettings):\n",
    "                print(\"FINAL_TRAIN: [DBG] AllFoldScores: \", approach, everyLambda, allFoldScores[everyLambdaIndex])\n",
    "            eventualApproachParams.append((approach,invP,normN,bestLambda))\n",
    "            \n",
    "        finalModels = None\n",
    "        finalModelFileName = outputFile + str(alpha) +'_finalmodels.pkl'\n",
    "        if os.path.exists(finalModelFileName):\n",
    "            g = open(finalModelFileName, 'rb')\n",
    "            finalModels = pickle.load(g)\n",
    "            g.close()\n",
    "            print (\"Expt2: [LOG]\\t Loaded trained final models from \", finalModelFileName)\n",
    "        else:\n",
    "            finalModels = Parallel(n_jobs = -1, verbose = 0)(delayed(FINAL_TRAIN)(approachTup, args.metric, \n",
    "                                        partialObservations, startTuple)\n",
    "                                        for approachTup in eventualApproachParams)\n",
    "            g = open(finalModelFileName, 'wb')\n",
    "            pickle.dump(finalModels, g, -1)\n",
    "            g.close()\n",
    "            print (\"Expt2: [LOG]\\t Saved trained final models to \", finalModelFileName)\n",
    "        \n",
    "        for approachID, approachTuple in enumerate(eventualApproachParams):\n",
    "            resultTuple = finalModels[approachID]\n",
    "            finalBiasMode = approachTuple[3][3]\n",
    "            finalBias = True\n",
    "            if finalBiasMode == 'None':\n",
    "                finalBias = False\n",
    "            predictedY = MF.PREDICTED_SCORES(resultTuple[0], resultTuple[1], \\\n",
    "                                resultTuple[2], resultTuple[3], resultTuple[4], use_bias = finalBias)\n",
    "\n",
    "            metricValue = currMetric(ML100KCompleteTest, predictedY, None)[0]\n",
    "            print (\"Expt2: [LOG] \", approachTuple[0], \"\\t Eventual result:\", metricValue)\n",
    "            sys.stdout.flush()\n",
    "            updateResults(metricValue, approachTuple[0], ind)    \n",
    "        \n",
    "        #Dump results after each alpha. Overwrite if needed.\n",
    "        outputData = (approaches, approachDict, alphas, allEstimates)\n",
    "        g = open(outputFile + args.estimators +'.pkl', 'wb')\n",
    "        pickle.dump(outputData, g, -1)\n",
    "        g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb # for full description of the bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a818037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17015479",
   "metadata": {},
   "source": [
    "## Expt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e09fb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import Expt2\n",
    "# import MF\n",
    "# import Metrics\n",
    "import numpy\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e0d24c0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def learn(data, logger, lambdas=None, seed=None, numDims=None, approach=None, metric=None, raw_metric=None,\n",
    "          output_name=None, propensities_desc=None):\n",
    "    clipVals = [-1]\n",
    "    biasModes = ['Free', 'Regularized']\n",
    "    numpy.random.seed(seed)\n",
    "\n",
    "    numBiasModes = len(biasModes)\n",
    "    numLambdas = len(lambdas)\n",
    "    numDimSettings = len(numDims)\n",
    "    numClipSettings = len(clipVals)\n",
    "    numParamSettings = numLambdas * numDimSettings * numClipSettings * numBiasModes\n",
    "\n",
    "    paramSettings = list(itertools.product(lambdas, numDims, clipVals, biasModes))\n",
    "    numApproaches = 1\n",
    "\n",
    "    selfMatrix = data.train\n",
    "\n",
    "    logger.log(\"Starting learning...\")\n",
    "    logger.log(\"\\t-metric: \" + raw_metric, 2)\n",
    "    logger.log(\"\\t-lambda values: \" + str(lambdas), 2)\n",
    "    logger.log(\"\\t-dimension values: \" + str(numDims), 2)\n",
    "    logger.log(\"\\t-propensity scoring method: \" + propensities_desc)\n",
    "    if data.propensities is not None:\n",
    "        invP = numpy.reciprocal(data.propensities)\n",
    "        invP = numpy.ma.array(invP, dtype=numpy.longdouble, copy=False,\n",
    "                              mask=numpy.ma.getmask(selfMatrix), fill_value=0, hard_mask=True)\n",
    "    else:\n",
    "        invP = None\n",
    "\n",
    "    foldScores = numpy.zeros((numApproaches, 4, numParamSettings), dtype=numpy.float)\n",
    "\n",
    "    observationIndices = numpy.ma.nonzero(selfMatrix)\n",
    "    numObservations = numpy.ma.count(selfMatrix)\n",
    "\n",
    "    shuffleIndices = numpy.random.permutation(numObservations)\n",
    "    fractionObservations = int(numObservations / 4)\n",
    "    firstFold = shuffleIndices[:fractionObservations]\n",
    "    secondFold = shuffleIndices[fractionObservations:2 * fractionObservations]\n",
    "    thirdFold = shuffleIndices[2 * fractionObservations:3 * fractionObservations]\n",
    "    fourthFold = shuffleIndices[3 * fractionObservations:]\n",
    "\n",
    "    logger.log(\"Split %d observations into folds. Fold sizes: %s\" %\n",
    "               (len(shuffleIndices), str([len(firstFold), len(secondFold), len(thirdFold), len(fourthFold)])),\n",
    "               2)\n",
    "\n",
    "    for fold in xrange(4):\n",
    "        logger.log(\"Learning on fold %d \" % fold)\n",
    "        trainObservations = numpy.ma.copy(selfMatrix)\n",
    "        testObservations = numpy.ma.copy(selfMatrix)\n",
    "\n",
    "        if fold == 0:\n",
    "            trainObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                numpy.ma.masked\n",
    "\n",
    "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                numpy.ma.masked\n",
    "        elif fold == 1:\n",
    "            trainObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                numpy.ma.masked\n",
    "\n",
    "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                numpy.ma.masked\n",
    "        elif fold == 2:\n",
    "            trainObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                numpy.ma.masked\n",
    "\n",
    "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                numpy.ma.masked\n",
    "        elif fold == 3:\n",
    "            trainObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                numpy.ma.masked\n",
    "\n",
    "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                numpy.ma.masked\n",
    "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                numpy.ma.masked\n",
    "\n",
    "        # Get starting params by SVD\n",
    "#         startTuple = Expt2.INIT_PARAMS(trainObservations, 40)\n",
    "        startTuple = INIT_PARAMS(trainObservations, 40)\n",
    "        normN = \"Vanilla\"\n",
    "        approachIndex = 0\n",
    "\n",
    "#         modelsPerLambda = Parallel(n_jobs=-1, verbose=0)(delayed(Expt2.MF_TRAIN)(param,\n",
    "#                                                                                  trainObservations, invP, normN,\n",
    "#                                                                                  raw_metric, startTuple)\n",
    "#                                                          for param in paramSettings)\n",
    "        modelsPerLambda = Parallel(n_jobs=-1, verbose=0)(delayed(MF_TRAIN)(param,\n",
    "                                                                                 trainObservations, invP, normN,\n",
    "                                                                                 raw_metric, startTuple)\n",
    "                                                         for param in paramSettings)\n",
    "\n",
    "        for lambdaIndex, eachModel in enumerate(modelsPerLambda):\n",
    "            selectedBiasMode = paramSettings[lambdaIndex][3]\n",
    "            selectedBias = True\n",
    "            if selectedBiasMode == 'None':\n",
    "                selectedBias = False\n",
    "            predictedY = MF.PREDICTED_SCORES(eachModel[0], eachModel[1],\n",
    "                                             eachModel[2], eachModel[3], eachModel[4], use_bias=selectedBias)\n",
    "\n",
    "            score = None\n",
    "            if invP is not None:\n",
    "                score = metric(testObservations, predictedY, 4.0 * invP)\n",
    "            else:\n",
    "                score = metric(testObservations, predictedY, invP)\n",
    "            score = score[0]\n",
    "            foldScores[approachIndex, fold, lambdaIndex] = score\n",
    "\n",
    "            logger.log(\"\\tLambda/NumDims: \" + str(paramSettings[lambdaIndex]) +\n",
    "                       \", Test Fold Score: \" + str(score), 2)\n",
    "\n",
    "    eventualApproachParams = []\n",
    "\n",
    "    normN = \"Vanilla\"\n",
    "    approachIndex = 0\n",
    "    approachScores = foldScores[approachIndex, :, :]\n",
    "    allFoldScores = approachScores.sum(axis=0, dtype=numpy.float)\n",
    "    bestLambdaIndex = numpy.argmin(allFoldScores)\n",
    "    bestLambda = paramSettings[bestLambdaIndex]\n",
    "    logger.log(\"Retraining with best hyperparameter values: \" + str(bestLambda))\n",
    "    logger.log(\"Chosen from average cross-validation performance:\", 2)\n",
    "    for everyLambdaIndex, everyLambda in enumerate(paramSettings):\n",
    "        logger.log(\"\\t\" + str(everyLambda) + \": \" +  str(allFoldScores[everyLambdaIndex]), 2)\n",
    "    eventualApproachParams.append((approach, invP, normN, bestLambda))\n",
    "\n",
    "#     finalModels = Parallel(n_jobs=-1, verbose=0)(delayed(Expt2.FINAL_TRAIN)(approachTup,\n",
    "#                                                                             raw_metric, selfMatrix, startTuple)\n",
    "#                                                  for approachTup in eventualApproachParams)\n",
    "    finalModels = Parallel(n_jobs=-1, verbose=0)(delayed(FINAL_TRAIN)(approachTup,\n",
    "                                                                            raw_metric, selfMatrix, startTuple)\n",
    "                                                 for approachTup in eventualApproachParams)\n",
    "\n",
    "    for approachID, approachTuple in enumerate(eventualApproachParams):\n",
    "        resultTuple = finalModels[approachID]\n",
    "        finalBiasMode = approachTuple[3][3]\n",
    "        finalBias = True\n",
    "        if finalBiasMode == 'None':\n",
    "            finalBias = False\n",
    "\n",
    "        predictedY = MF.PREDICTED_SCORES(resultTuple[0], resultTuple[1],\n",
    "                                         resultTuple[2], resultTuple[3], resultTuple[4], use_bias=finalBias)\n",
    "        numpy.savetxt(output_name, predictedY)\n",
    "        logger.log(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c9ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb27e1f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1760f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.append(os.path.dirname(os.path.realpath(__file__)) \n",
    "# + os.path.sep + os.path.pardir + os.path.sep + \"lib\")\n",
    "\n",
    "# import Metrics\n",
    "# import Expt3\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37bbda5f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Files(object):\n",
    "    def __init__(self, train, propensities):\n",
    "        self.train = train\n",
    "        self.propensities = propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "181cb789",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self, verbosity_level=1):\n",
    "        self._verbosity_level = verbosity_level\n",
    "\n",
    "    def log(self, message, level=1):\n",
    "        if level <= self._verbosity_level:\n",
    "            print (message)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "973dbd7c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_ratings(filename):\n",
    "    try:\n",
    "        raw_matrix = numpy.loadtxt(filename)\n",
    "        return numpy.ma.array(raw_matrix, dtype=numpy.int, copy=False,\n",
    "                              mask=raw_matrix <= 0, fill_value=0, hard_mask=True)\n",
    "    except:\n",
    "        print (\"Error: Could not load rating file '%s'\" % filename)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55fa1bf2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_propensities(filename):\n",
    "    try:\n",
    "        return numpy.loadtxt(filename)\n",
    "    except:\n",
    "        print (\"Error: Could not load propensities.\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53e5a645",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def check_writeable(filename):\n",
    "    try:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pass\n",
    "        os.remove(filename)\n",
    "        return True, \"\"\n",
    "    except IOError:\n",
    "        print (\"Error: Could not open file '%s' for writing\" % filename)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9f04891",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false # 去掉以运行\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Propensity-scored Matrix Factorization.')\n",
    "    parser.add_argument(\"--ratings\", \"-r\", type=str, required=True,\n",
    "                        help=\"ratings matrix in ASCII format\")\n",
    "    parser.add_argument(\"--propensities\", \"-p\", type=str, default=\"\",\n",
    "                        help=\"propensities matrix in ASCII format (optional)\")\n",
    "    parser.add_argument(\"--completed\", \"-c\", type=str, default=\"completed_ratings.ascii\",\n",
    "                        help=\"filename for completed matrix\")\n",
    "    parser.add_argument('--metric', '-m', metavar='M', type=str, choices=[\"MSE\", \"MAE\"],\n",
    "                        help='Metric to be optimized', default='MSE')\n",
    "    parser.add_argument('--lambdas', '-l', metavar='L', type=str,\n",
    "                        help='Lambda values', default='0.008,0.04,0.2,1,5,25,125')\n",
    "    parser.add_argument('--numdims', '-n', metavar='N', type=str,\n",
    "                        help='Dimension values', default='5,10,20,40')\n",
    "    parser.add_argument('--seed', '-s', metavar='S', type=int,\n",
    "                        help='Seed for numpy.random', default=387)\n",
    "    parser.add_argument(\"--verbosity\", \"-v\", type=int, choices=[0, 1, 2],\n",
    "                        help=\"output verbosity (default = 2)\", default=2)\n",
    "\n",
    "    args = parser.parse_args() # 这一行有bug，在Expt2 也有类似的bug\n",
    "    check_writeable(args.completed)\n",
    "    my_logger = Logger(args.verbosity)\n",
    "\n",
    "    lambdas = []\n",
    "    tokens = args.lambdas.strip().split(',')\n",
    "    for token in tokens:\n",
    "        lambdas.append(float(token))\n",
    "\n",
    "    numDims = []\n",
    "    tokens = args.numdims.strip().split(',')\n",
    "    for token in tokens:\n",
    "        numDims.append(int(token))\n",
    "\n",
    "    train = load_ratings(args.ratings)\n",
    "    if args.propensities:\n",
    "        propensities = load_propensities(args.propensities)\n",
    "        propensities_desc = \"IPS using \" + args.propensities\n",
    "    else:\n",
    "        propensities = None\n",
    "        propensities_desc = \"naive (uniform)\"\n",
    "    data = Files(train, propensities)\n",
    "\n",
    "    if args.metric == 'MSE':\n",
    "        metric = Metrics.MSE\n",
    "    elif args.metric == 'MAE':\n",
    "        metric = Metrics.MAE\n",
    "\n",
    "    Expt3.learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
    "          seed=args.seed, raw_metric=args.metric, output_name=args.completed, propensities_desc=propensities_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43de12e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemExit\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5896/598901849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                         help=\"output verbosity (default = 2)\", default=2)\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mcheck_writeable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompleted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmy_logger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbosity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1766\u001b[0m     \u001b[1;31m# =====================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unrecognized arguments: %s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1798\u001b[0m         \u001b[1;31m# parse the arguments and exit if there are any errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1800\u001b[1;33m             \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2033\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrequired_actions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2034\u001b[1;33m             self.error(_('the following arguments are required: %s') %\n\u001b[0m\u001b[0;32m   2035\u001b[0m                        ', '.join(required_actions))\n\u001b[0;32m   2036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2519\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2520\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'prog'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'message'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2521\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anaconda\\lib\\argparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m         \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb # for full description of the bug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4981b90",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7457ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "# sys.path.append(os.path.dirname(os.path.realpath(__file__)) \n",
    "# + os.path.sep + os.path.pardir + os.path.sep + \"lib\")\n",
    "\n",
    "# import Metrics\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "133fee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings(filename):\n",
    "    try:\n",
    "        raw_matrix = numpy.loadtxt(filename)\n",
    "        return numpy.ma.array(raw_matrix, dtype=numpy.int, copy=False,\n",
    "                              mask=raw_matrix <= 0, fill_value=0, hard_mask=True)\n",
    "    except:\n",
    "        print (\"Error: Could not load rating file '%s'\" % filename)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20ae8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_completed(filename):\n",
    "    try:\n",
    "        return numpy.loadtxt(filename)\n",
    "    except:\n",
    "        print (\"Error: Could not load rating file '%s'\" % filename)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "以下存在同样的parse argument bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4318d966",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --test TEST --completed COMPLETED\n",
      "ipykernel_launcher.py: error: the following arguments are required: --test/-t, --completed/-c\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%%script false #去掉以运行\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Propensity-scored Matrix Factorization Evaluation.')\n",
    "    parser.add_argument(\"--test\", \"-t\", type=str,\n",
    "                        help=\"test ratings (uniformly sampled) in ASCII format\", required=True)\n",
    "    parser.add_argument(\"--completed\", \"-c\", type=str,\n",
    "                        help=\"filename for completed matrix\", required=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    completed = load_completed(args.completed)\n",
    "    test = load_ratings(args.test)\n",
    "\n",
    "    for metric in [Metrics.MSE, Metrics.MAE]:\n",
    "        metricValue = metric(test, completed, None)[0]\n",
    "        print (metric.__name__ + \": \" + str(metricValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907525f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
