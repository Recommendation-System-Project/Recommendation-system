{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bc2d88",
   "metadata": {},
   "source": [
    "# IPS Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd209b63",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf9808",
   "metadata": {
    "code_folding": [
     0,
     1,
     12
    ]
   },
   "outputs": [],
   "source": [
    "class Jitter:\n",
    "    def __init__(self, cut_off, num_users, num_items):\n",
    "        self.jitter = 1e-7 * numpy.random.standard_normal((num_users, num_items))\n",
    "        discountParams = 2.0 + numpy.array(range(num_items), dtype = numpy.longdouble)\n",
    "        self.discountParams = numpy.reciprocal(numpy.log2(discountParams))\n",
    "        self.cutOff = min(cut_off, num_items)\n",
    "        self.discountParams[self.cutOff:] = 0.0\n",
    "\n",
    "        print (\"Jitter.init: [DBG]\\t (NumUsers, NumItems)\"), num_users, num_items, (\"\\t Sum DiscountFactors\"),\\\n",
    "                self.discountParams.sum(dtype = numpy.longdouble), (\"\\t [Requested/Set] Cut-off:\"), \\\n",
    "                cut_off, self.cutOff\n",
    "\n",
    "    def rank(self, predicted_matrix):\n",
    "        transformedPredictions = -numpy.ma.add(predicted_matrix, self.jitter)\n",
    "        sortedPredictions = numpy.ma.argsort(transformedPredictions, axis = 1)\n",
    "        return sortedPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ab6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgJitter = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c74ff",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose = False):\n",
    "    numObservations = numpy.ma.count(observed_ratings)\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "    inversePropensities = None\n",
    "    if inverse_propensities is None:\n",
    "        inversePropensities = numpy.ones((numUsers, numItems), dtype = numpy.longdouble) * scale /\\\n",
    "                            numObservations\n",
    "    else:\n",
    "        inversePropensities = numpy.array(inverse_propensities, dtype = numpy.longdouble, copy = True)\n",
    "\n",
    "    inversePropensities = numpy.ma.array(inversePropensities, dtype = numpy.longdouble, copy = False, \n",
    "                            mask = numpy.ma.getmask(observed_ratings), fill_value = 0, hard_mask = True)\n",
    " \n",
    "    if verbose:\n",
    "        print (\"Metrics.SET_PROPENSITIES: [LOG]\\t NumUsers, NumItems, NumObservations\"), \\\n",
    "            numUsers, numItems, numObservations\n",
    "        print (\"Metrics.SET_PROPENSITIES: [DBG]\\t Sum of observed inverse propensities \"), \\\n",
    "            numpy.ma.sum(inversePropensities, dtype = numpy.longdouble), \\\n",
    "            (\"(=? NumUsers * NumItems)\"), numUsers * numItems\n",
    "\n",
    "    return inversePropensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f62c0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MSE'):\n",
    "    delta = numpy.ma.subtract(predicted_ratings, observed_ratings)\n",
    "    rectifiedDelta = None\n",
    "    if mode == 'MSE':\n",
    "        rectifiedDelta = numpy.square(delta)\n",
    "    elif mode == 'MAE':\n",
    "        rectifiedDelta = numpy.ma.abs(delta)\n",
    "    else:\n",
    "        print (\"Metrics.ITEMWISE_METRICS: [ERR]\\t Unrecognized itemwise metric \"), mode\n",
    "        sys.exit(0)\n",
    "\n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
    "\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "\n",
    "    observedError = numpy.ma.multiply(rectifiedDelta, inversePropensities)\n",
    "    cumulativeError = numpy.ma.sum(observedError, dtype = numpy.longdouble)\n",
    "    vanillaMetric = cumulativeError / scale\n",
    "    \n",
    "    globalNormalizer = numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "    selfNormalizedMetric = cumulativeError / globalNormalizer\n",
    "    \n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perUserError = numpy.ma.sum(observedError, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserEstimate = numpy.ma.divide(perUserError, perUserNormalizer)\n",
    "    userNormalizedMetric = numpy.ma.sum(perUserEstimate, dtype = numpy.longdouble) / numUsers\n",
    "\n",
    "    perItemNormalizer = numpy.ma.sum(inversePropensities, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemNormalizer = numpy.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perItemError = numpy.ma.sum(observedError, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemEstimate = numpy.ma.divide(perItemError, perItemNormalizer)\n",
    "    itemNormalizedMetric = numpy.ma.sum(perItemEstimate, dtype = numpy.longdouble) / numItems\n",
    "   \n",
    "    if verbose:\n",
    "        print (\"Metrics.ITEMWISE_METRICS: [LOG]\\t Vanilla, SelfNormalized, UserNormalized, ItemNormalized\"), \\\n",
    "            vanillaMetric, selfNormalizedMetric, userNormalizedMetric, itemNormalizedMetric\n",
    "\n",
    "    return vanillaMetric, selfNormalizedMetric, userNormalizedMetric, itemNormalizedMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ab891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(observed_ratings, predicted_ratings, inverse_propensities, verbose = False):\n",
    "    return ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7db392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(observed_ratings, predicted_ratings, inverse_propensities, verbose = False):\n",
    "    return ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043fac",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def DCG(observed_ratings, predicted_ratings, inverse_propensities, cut_off = 50, verbose = False):\n",
    "    global dcgJitter\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "\n",
    "    if dcgJitter is None or dcgJitter.cutOff != cut_off:\n",
    "        dcgJitter = Jitter(cut_off, numUsers, numItems)\n",
    " \n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
    "    \n",
    "    predictedRankings = dcgJitter.rank(predicted_ratings)\n",
    "    weightedGain = numpy.ma.multiply(observed_ratings, inversePropensities)\n",
    " \n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    staticIndices = numpy.ogrid[0:numUsers, 0:numItems]\n",
    "    rankedGains = weightedGain[staticIndices[0], predictedRankings]\n",
    "    perUserDCG = numpy.ma.dot(rankedGains, dcgJitter.discountParams)\n",
    "\n",
    "    dcgValue = numpy.ma.sum(perUserDCG, dtype = numpy.longdouble) / numUsers\n",
    "    snDCGValue = dcgValue * scale / numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "\n",
    "    perUserNormalizedEstimates = numpy.ma.divide(perUserDCG, perUserNormalizer)\n",
    "    uDCGValue = numItems * numpy.ma.sum(perUserNormalizedEstimates, dtype = numpy.longdouble) / numUsers\n",
    "    \n",
    "    if verbose:\n",
    "        print (\"Metrics.DCG: [LOG]\\t DCG, SN-DCG, UN-DCG, IN-DCG\"), dcgValue, snDCGValue, uDCGValue, 0.0\n",
    "    return dcgValue, snDCGValue, uDCGValue, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee911a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def CG(observed_ratings, selected_items, inverse_propensities, verbose = False):\n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
    "\n",
    "    clippedSelections = numpy.clip(selected_items, 0, 1)\n",
    "    weightedGain = numpy.ma.multiply(observed_ratings, inversePropensities)\n",
    "    cumulativeGain = numpy.ma.multiply(weightedGain, clippedSelections)\n",
    "    \n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "\n",
    "    globalGain = numpy.ma.sum(cumulativeGain, dtype = numpy.longdouble)\n",
    "    globalNormalizer = numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "\n",
    "    cg = globalGain / numUsers\n",
    "    snCG = numItems * globalGain / globalNormalizer\n",
    "\n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perUserGain = numpy.ma.sum(cumulativeGain, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserEstimate = numpy.ma.divide(perUserGain, perUserNormalizer)\n",
    "    unCG = numItems * numpy.ma.sum(perUserEstimate, dtype = numpy.longdouble) / numUsers\n",
    "\n",
    "    perItemNormalizer = numpy.ma.sum(inversePropensities, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemNormalizer = numpy.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perItemGain = numpy.ma.sum(cumulativeGain, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemEstimate = numpy.ma.divide(perItemGain, perItemNormalizer)\n",
    "    inCG = numpy.ma.sum(perItemEstimate, dtype = numpy.longdouble)\n",
    "       \n",
    "    if verbose:\n",
    "        print (\"Metrics.CG: [LOG]\\t CG, SN-CG, UN-CG, IN-CG\"), cg, snCG, unCG, inCG\n",
    "    return cg, snCG, unCG, inCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332a822",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    shape = (5,3)\n",
    "    a = numpy.random.randint(0,5, size=shape)\n",
    "    b = numpy.random.randint(0,5, size=shape)\n",
    "    \n",
    "    print (\"[MAIN]\\t True ratings:\")\n",
    "    print (a)\n",
    "    print (\"[MAIN]\\t Predicted ratings:\")\n",
    "    print (b)\n",
    "    \n",
    "    inversePropensities = numpy.random.random(shape)\n",
    "    print (\"[MAIN]\\t Propensities:\")\n",
    "    print (inversePropensities)\n",
    "    obs = numpy.random.random(shape)\n",
    "    obs = obs < inversePropensities\n",
    "    inversePropensities = numpy.reciprocal(inversePropensities)\n",
    "    print (\"[MAIN]\\t Inverse Propensities:\")\n",
    "    print (inversePropensities)\n",
    "\n",
    "    print (\"[MAIN]\\t Observations:\")\n",
    "    print (obs)\n",
    "    \n",
    "    observed_a = numpy.ma.array(a, dtype = numpy.longdouble, copy = True, \n",
    "                            mask = numpy.logical_not(obs), fill_value = 0, hard_mask = True)\n",
    "     \n",
    "    print (\"[MAIN]\\t MSE: Vanilla, SN, UN, IN:\"),\n",
    "    MSE(observed_a, b, inversePropensities, verbose = True)\n",
    "    print (\"[MAIN]\\t MAE: Vanilla, SN, UN, IN:\")\n",
    "    MAE(observed_a, b, inversePropensities, verbose = True)\n",
    "    print (\"[MAIN]\\t DCG: Vanilla, SN, UN, IN:\")\n",
    "    DCG(observed_a, b, inversePropensities, cut_off = 50, verbose = True)\n",
    "    \n",
    "    print (\"[MAIN]\\t CG: Vanilla, SN, UN, IN:\")\n",
    "    CG(observed_a, b, inversePropensities, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a882d8",
   "metadata": {},
   "source": [
    "## MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cff22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import scipy.optimize\n",
    "# import sys\n",
    "# import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786c1b3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def PREDICTED_SCORES(user_vectors, item_vectors, user_biases, item_biases, global_bias, use_bias = True):\n",
    "    rawScores = numpy.dot(user_vectors, item_vectors.T)\n",
    "    if use_bias:\n",
    "        biasedScores = rawScores + user_biases[:,None] + item_biases[None,:] + global_bias\n",
    "        return biasedScores\n",
    "    else:\n",
    "        return rawScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fca099",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def GENERATE_MATRIX(observed_ratings, inverse_propensities, l2_regularization, num_dimensions, normalization,\n",
    "        bias_mode = 'Regularized', mode = 'MSE', start_vec = None, verbose = False):\n",
    "\n",
    "    metricMode = None\n",
    "    if mode == 'MSE':\n",
    "        metricMode = 1\n",
    "    elif mode == 'MAE':\n",
    "        metricMode = 2\n",
    "    else:\n",
    "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Metric not supported:\", mode)\n",
    "        sys.exit(0)\n",
    "\n",
    "#     inversePropensities = Metrics.SET_PROPENSITIES(observed_ratings, inverse_propensities, False)\n",
    "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, False)\n",
    "\n",
    "    numUsers, numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "    numObservations = numpy.ma.count(observed_ratings)\n",
    "\n",
    "    perUserNormalizer = numpy.ma.sum(inversePropensities, axis = 1, dtype = numpy.longdouble)\n",
    "    perUserNormalizer = numpy.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
    "\n",
    "    perItemNormalizer = numpy.ma.sum(inversePropensities, axis = 0, dtype = numpy.longdouble)\n",
    "    perItemNormalizer = numpy.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
    "\n",
    "    globalNormalizer = numpy.ma.sum(inversePropensities, dtype = numpy.longdouble)\n",
    "\n",
    "    normalizedPropensities = None\n",
    "    if normalization == 'Vanilla':\n",
    "        normalizedPropensities = inversePropensities\n",
    "    elif normalization == 'SelfNormalized':\n",
    "        normalizedPropensities = scale * numpy.ma.divide(inversePropensities, globalNormalizer)\n",
    "    elif normalization == 'UserNormalized':\n",
    "        normalizedPropensities = numItems * numpy.ma.divide(inversePropensities, perUserNormalizer[:, None])\n",
    "    elif normalization == 'ItemNormalized':\n",
    "        normalizedPropensities = numUsers * numpy.ma.divide(inversePropensities, perItemNormalizer[None, :])\n",
    "    else:\n",
    "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Normalization not supported:\", normalization)\n",
    "        sys.exit(0)\n",
    "    \n",
    "    useBias = None\n",
    "    regularizeBias = None\n",
    "    if bias_mode == 'None':\n",
    "        useBias = False\n",
    "        regularizeBias = False\n",
    "    elif bias_mode == 'Regularized':\n",
    "        useBias = True\n",
    "        regularizeBias = True\n",
    "    elif bias_mode == 'Free':\n",
    "        useBias = True\n",
    "        regularizeBias = False\n",
    "    else:\n",
    "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Bias mode not supported:\", bias_mode)\n",
    "        sys.exit(0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"MF.GENERATE_MATRIX: [LOG]\\t Lamda:\", l2_regularization, \"\\t NumDims:\", num_dimensions,\\\n",
    "            \"\\t Normalization:\", normalization, \"\\t Metric:\", mode, \"\\t BiasMode:\", bias_mode)\n",
    "\n",
    "    normalizedPropensities = numpy.ma.filled(normalizedPropensities, 0.0)\n",
    "    observedRatings = numpy.ma.filled(observed_ratings, 0)\n",
    "    \n",
    "    def Mat2Vec(user_vectors, item_vectors, user_biases, item_biases, global_bias):\n",
    "        allUserParams = numpy.concatenate((user_vectors, user_biases[:,None]), axis = 1)\n",
    "        allItemParams = numpy.concatenate((item_vectors, item_biases[:,None]), axis = 1)\n",
    "        \n",
    "        allParams = numpy.concatenate((allUserParams, allItemParams), axis = 0)\n",
    "        paramVector = numpy.reshape(allParams, (numUsers + numItems)*(num_dimensions + 1))\n",
    "        paramVector = numpy.concatenate((paramVector, [global_bias]))\n",
    "        return paramVector.astype(numpy.float)\n",
    "        \n",
    "    def Vec2Mat(paramVector):\n",
    "        globalBias = paramVector[-1]\n",
    "        remainingParams = paramVector[:-1]\n",
    "        allParams = numpy.reshape(remainingParams, (numUsers + numItems, num_dimensions + 1))\n",
    "        allUserParams = allParams[0:numUsers,:]\n",
    "        allItemParams = allParams[numUsers:, :]\n",
    "        \n",
    "        userVectors = (allUserParams[:,0:-1]).astype(numpy.longdouble)\n",
    "        userBiases = (allUserParams[:,-1]).astype(numpy.longdouble)\n",
    "        \n",
    "        itemVectors = (allItemParams[:,0:-1]).astype(numpy.longdouble)\n",
    "        itemBiases = (allItemParams[:,-1]).astype(numpy.longdouble)\n",
    "        return userVectors, itemVectors, userBiases, itemBiases, globalBias\n",
    "    \n",
    "    def Objective(paramVector):\n",
    "        userVectors, itemVectors, userBiases, itemBiases, globalBias = Vec2Mat(paramVector)\n",
    "        biasedScores = PREDICTED_SCORES(userVectors, itemVectors, userBiases, itemBiases, globalBias, useBias)\n",
    "\n",
    "        delta = numpy.subtract(biasedScores, observedRatings)\n",
    "        loss = None\n",
    "        if metricMode == 1:\n",
    "            loss = numpy.square(delta)\n",
    "        elif metricMode == 2:\n",
    "            loss = numpy.abs(delta)\n",
    "        else:\n",
    "            sys.exit(0)\n",
    "\n",
    "        weightedLoss = numpy.multiply(loss, normalizedPropensities)\n",
    "        objective = numpy.sum(weightedLoss, dtype = numpy.longdouble)\n",
    "\n",
    "        gradientMultiplier = None\n",
    "        if metricMode == 1:\n",
    "            gradientMultiplier = numpy.multiply(normalizedPropensities, 2 * delta)\n",
    "        elif metricMode == 2:\n",
    "            gradientMultiplier = numpy.zeros(numpy.shape(delta), dtype = numpy.int)\n",
    "            gradientMultiplier[delta > 0] = 1\n",
    "            gradientMultiplier[delta < 0] = -1\n",
    "            gradientMultiplier = numpy.multiply(normalizedPropensities, gradientMultiplier)\n",
    "        else:\n",
    "            sys.exit(0)\n",
    "\n",
    "        userVGradient = numpy.dot(gradientMultiplier, itemVectors)\n",
    "        itemVGradient = numpy.dot(gradientMultiplier.T, userVectors)\n",
    "\n",
    "        userBGradient = None\n",
    "        itemBGradient = None\n",
    "        globalBGradient = None\n",
    "        if useBias:\n",
    "            userBGradient = numpy.sum(gradientMultiplier, axis = 1, dtype = numpy.longdouble)\n",
    "            itemBGradient = numpy.sum(gradientMultiplier, axis = 0, dtype = numpy.longdouble)\n",
    "            globalBGradient = numpy.sum(gradientMultiplier, dtype = numpy.longdouble)\n",
    "        else:\n",
    "            userBGradient = numpy.zeros(numpy.shape(userBiases), dtype = numpy.longdouble)\n",
    "            itemBGradient = numpy.zeros(numpy.shape(itemBiases), dtype = numpy.longdouble)\n",
    "            globalBGradient = 0.0\n",
    "\n",
    "        if l2_regularization > 0:\n",
    "            scaledPenalty = 1.0 * l2_regularization * scale / (numUsers + numItems)\n",
    "            if regularizeBias:\n",
    "                scaledPenalty /= (num_dimensions + 1)\n",
    "            else:\n",
    "                scaledPenalty /= num_dimensions\n",
    "\n",
    "            userVGradient += 2 * scaledPenalty * userVectors\n",
    "            itemVGradient += 2 * scaledPenalty * itemVectors\n",
    "          \n",
    "            objective += scaledPenalty * numpy.sum(numpy.square(userVectors), dtype = numpy.longdouble)\n",
    "            objective += scaledPenalty * numpy.sum(numpy.square(itemVectors), dtype = numpy.longdouble)\n",
    " \n",
    "            if regularizeBias:\n",
    "                userBGradient += 2 * scaledPenalty * userBiases\n",
    "                itemBGradient += 2 * scaledPenalty * itemBiases\n",
    "                globalBGradient += 2 * scaledPenalty * globalBias\n",
    "                objective += scaledPenalty * numpy.sum(numpy.square(userBiases), dtype = numpy.longdouble)\n",
    "                objective += scaledPenalty * numpy.sum(numpy.square(itemBiases), dtype = numpy.longdouble)\n",
    "                objective += scaledPenalty * globalBias * globalBias\n",
    "            \n",
    "        gradient = Mat2Vec(userVGradient, itemVGradient, userBGradient, itemBGradient, globalBGradient)\n",
    "\n",
    "        if verbose:\n",
    "            print( \".\",)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        return objective, gradient\n",
    "    \n",
    "    def ObjectiveOnly(paramVector):\n",
    "        objective, gradient = Objective(paramVector)\n",
    "        return objective\n",
    "    def GradientOnly(paramVector):\n",
    "        objective, gradient = Objective(paramVector)\n",
    "        return gradient\n",
    "    \n",
    "    userVectorsInit = None\n",
    "    itemVectorsInit = None\n",
    "    userBiasesInit = None\n",
    "    itemBiasesInit = None\n",
    "    globalBiasInit = None\n",
    "    if start_vec is None:\n",
    "        userVectorsInit = numpy.random.standard_normal((numUsers, num_dimensions))\n",
    "        itemVectorsInit = numpy.random.standard_normal((numItems, num_dimensions))\n",
    "        userBiasesInit = numpy.zeros(numUsers, dtype = numpy.float)\n",
    "        itemBiasesInit = numpy.zeros(numItems, dtype = numpy.float)\n",
    "        globalBiasInit = 0\n",
    "    else:\n",
    "        userVectorsInit = start_vec[0]\n",
    "        itemVectorsInit = start_vec[1]\n",
    "        userBiasesInit = start_vec[2]\n",
    "        itemBiasesInit = start_vec[3]\n",
    "        globalBiasInit = start_vec[4]\n",
    "    \n",
    "    startVector = Mat2Vec(userVectorsInit, itemVectorsInit, userBiasesInit, itemBiasesInit, globalBiasInit)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"MF.GENERATE_MATRIX: [DBG]\\t Checking gradients\")\n",
    "        print(scipy.optimize.check_grad(ObjectiveOnly, GradientOnly, startVector))\n",
    "\n",
    "    ops = {'maxiter': 2000, 'disp': False, 'gtol': 1e-5,\\\n",
    "            'ftol': 1e-5, 'maxcor': 50}\n",
    "\n",
    "    result = scipy.optimize.minimize(fun = Objective, x0 = startVector,\n",
    "                    method = 'L-BFGS-B', jac = True, tol = 1e-5, options = ops)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "        print(\"MF.GENERATE_MATRIX: [DBG]\\t Optimization result:\", result['message'])\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return Vec2Mat(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b45200",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import scipy.sparse\n",
    "    \n",
    "    rows = [2,1,4,3,0,4,3]\n",
    "    cols = [0,2,1,1,0,0,0]\n",
    "    vals = [1,2,3,4,5,4,5]\n",
    "    checkY = scipy.sparse.coo_matrix((vals, (rows,cols)), dtype = numpy.int)\n",
    "    checkY = checkY.toarray()\n",
    "    checkY = numpy.ma.array(checkY, dtype = numpy.int, mask = checkY <= 0, hard_mask = True, copy = False)\n",
    "    print(\"[MAIN]\\t Partially observed ratings matrix\")\n",
    "    print(checkY)\n",
    "\n",
    "    randomPropensities = numpy.random.random(size = numpy.shape(checkY))\n",
    "    randomInvPropensities = numpy.reciprocal(randomPropensities)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, None, 1.0, 5, 'Vanilla',\n",
    "                                                'Regularized', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'Vanilla',\n",
    "                                                'Regularized', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'Vanilla',\n",
    "                                                'Regularized', 'MAE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'SelfNormalized',\n",
    "                                                'Regularized', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, None, 1.0, 5, 'Vanilla',\n",
    "                                                'Free', 'MSE', None, verbose = True)\n",
    "\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, randomInvPropensities, 1.0, 5, 'SelfNormalized',\n",
    "                                                'None', 'MSE', None, verbose = True)\n",
    "\n",
    "\n",
    "    print(\"[MAIN]\\t User vectors\")\n",
    "    print(userVectors)\n",
    "    print(\"[MAIN]\\t Item vectors\")\n",
    "    print(itemVectors)\n",
    "    print(\"[MAIN]\\t User biases\")\n",
    "    print(userBiases)\n",
    "    print(\"[MAIN]\\t Item biases\")\n",
    "    print(itemBiases)\n",
    "    print(\"[MAIN]\\t Global bias\")\n",
    "    print(globalBias)\n",
    "    \n",
    "    completeScores = PREDICTED_SCORES(userVectors, itemVectors, userBiases, itemBiases, globalBias, True)\n",
    "    print(\"[MAIN]\\t Predicted scores\")\n",
    "    print(completeScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480f2e8",
   "metadata": {},
   "source": [
    "## Expt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MF\n",
    "# import numpy\n",
    "import scipy.sparse.linalg\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MF_TRAIN(params, train_observations, inv_propensities, normalization, metric, start_vector):\n",
    "    retVal = None\n",
    "    actualStart = None\n",
    "    if start_vector is not None:\n",
    "        actualStart = (start_vector[0][:,0:params[1]], start_vector[1][:,0:params[1]],\n",
    "                        start_vector[2], start_vector[3], start_vector[4])\n",
    "\n",
    "    tempInvPropensities = None\n",
    "    if inv_propensities is not None:\n",
    "        tempInvPropensities = (4.0 / 3.0) * inv_propensities\n",
    "        if params[2] >= 0:\n",
    "            tempInvPropensities = numpy.clip(tempInvPropensities, a_min = 0, a_max = params[2])\n",
    "\n",
    "    retVal = MF.GENERATE_MATRIX(train_observations, tempInvPropensities, params[0], \n",
    "                                params[1], normalization, bias_mode = params[3], mode = metric, \n",
    "                                start_vec = actualStart, verbose = False)\n",
    "\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FINAL_TRAIN(approach_tuple, metric, observations, start_vector):\n",
    "    invP = approach_tuple[1]\n",
    "    normN = approach_tuple[2]\n",
    "    bestLambda = approach_tuple[3][0]\n",
    "    bestDims = approach_tuple[3][1]\n",
    "    bestClip = approach_tuple[3][2]\n",
    "    bestBias = approach_tuple[3][3]\n",
    "    actualStart = None\n",
    "    if start_vector is not None:\n",
    "        actualStart = (start_vector[0][:,0:bestDims], start_vector[1][:,0:bestDims],\n",
    "                        start_vector[2], start_vector[3], start_vector[4])\n",
    "\n",
    "    tempInvP = None\n",
    "    if bestClip < 0 or invP is None:\n",
    "        tempInvP = invP\n",
    "    else:\n",
    "        tempInvP = numpy.clip(invP, a_min = 0, a_max = bestClip)\n",
    "\n",
    "    retVal = MF.GENERATE_MATRIX(observations, tempInvP, bestLambda, bestDims, normN, bias_mode = bestBias,\n",
    "                        mode = metric, start_vec = actualStart)\n",
    "\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def INIT_PARAMS(partial_observations, num_dimensions):\n",
    "    averageObservedRating = numpy.ma.mean(partial_observations, dtype = numpy.longdouble)\n",
    "    completeRatings = numpy.ma.filled(partial_observations.astype(numpy.float), averageObservedRating)\n",
    "    numUsers, numItems = numpy.shape(partial_observations)\n",
    "\n",
    "    u,s,vt = scipy.sparse.linalg.svds(completeRatings, k = num_dimensions, ncv = 50, tol = 1e-7, which = 'LM', \n",
    "                        v0 = None, maxiter = 2000, return_singular_vectors = True)\n",
    "            \n",
    "    startTuple = (u, numpy.transpose(numpy.multiply(vt, s[:,None])), \n",
    "                     numpy.zeros(numUsers, dtype = numpy.longdouble), \n",
    "                     numpy.zeros(numItems, dtype = numpy.longdouble), \n",
    "                     averageObservedRating)\n",
    "    return startTuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9753b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRAIN_HELPER(approach, gold_inv_propensities, nb_inv_propensities):\n",
    "    invP = None\n",
    "    if approach == 'Naive':\n",
    "        invP = None\n",
    "    elif approach.startswith('Gold'):\n",
    "        invP = gold_inv_propensities\n",
    "    elif approach.startswith('NB'):\n",
    "        invP = nb_inv_propensities\n",
    "    else:\n",
    "        print (\"TRAIN_HELPER: [ERR] Unrecognized approach\", approach)\n",
    "        sys.exit(0)\n",
    "\n",
    "    normN = None\n",
    "    if approach == 'Naive' or approach.endswith('-IPS'):\n",
    "        normN = 'Vanilla'\n",
    "    elif approach.endswith('-SNIPS'):\n",
    "        normN = 'SelfNormalized'\n",
    "    elif approach.endswith('-UNIPS'):\n",
    "        normN = 'UserNormalized'\n",
    "    elif approach.endswith('-INIPS'):\n",
    "        normN = 'ItemNormalized'\n",
    "    else:\n",
    "        print (\"TRAIN_HELPER: [ERR] Unrecognized approach\", approach)\n",
    "        sys.exit(0)\n",
    "        \n",
    "    return invP, normN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "#     import Datasets\n",
    "    from lenskit.datasets import ML100K\n",
    "#     import Metrics\n",
    "    import Propensity\n",
    "    import pickle\n",
    "    import os\n",
    "    import itertools\n",
    "    from joblib import Parallel, delayed\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Semi-Synthetic Learning on ML100K.')\n",
    "    parser.add_argument('--seed', '-s', metavar='S', type=int, \n",
    "                        help='Seed for numpy.random', default=387)\n",
    "    parser.add_argument('--trial', '-t', metavar='T', type=int, \n",
    "                        help='Trial ID', default=1)\n",
    "    parser.add_argument('--alphas', '-a', metavar='A', type=str, \n",
    "                        help='Alpha values', default='1,0.5,0.25,0.125,0.0625,0.03125')\n",
    "    parser.add_argument('--lambdas', '-l', metavar='L', type=str, \n",
    "                        help='Lambda values', default='0.008,0.04,0.2,1,5,25,125')\n",
    "    parser.add_argument('--numdims', '-n', metavar='N', type=str, \n",
    "                        help='Dimension values', default='20')\n",
    "    parser.add_argument('--clips', '-c', metavar='C', type=str, \n",
    "                        help='Clip values', default='-1')\n",
    "    parser.add_argument('--estimators', '-e', metavar='E', type=str, \n",
    "                        help='Learning methods', default='Naive,Gold-IPS,Gold-SNIPS')\n",
    "    parser.add_argument('--metric', '-m', metavar='M', type=str, \n",
    "                        help='Metrics', default='MSE')\n",
    "                        \n",
    "    args = parser.parse_args()\n",
    "    numpy.random.seed(args.seed)\n",
    "    \n",
    "    approaches = args.estimators.strip().split(',')\n",
    "    \n",
    "    approachDict = {}\n",
    "    for approach in approaches:\n",
    "        approachDict[(approach, args.metric)] = len(approachDict)\n",
    "        \n",
    "    alphas = []\n",
    "    tokens = args.alphas.strip().split(',')\n",
    "    for token in tokens:\n",
    "        alphas.append(float(token))\n",
    "    \n",
    "    lambdas = []\n",
    "    tokens = args.lambdas.strip().split(',')\n",
    "    for token in tokens:\n",
    "        lambdas.append(float(token))\n",
    "        \n",
    "    numDims = []\n",
    "    tokens = args.numdims.strip().split(',')\n",
    "    for token in tokens:\n",
    "        numDims.append(int(token))\n",
    "    \n",
    "    clipVals = []\n",
    "    tokens = args.clips.strip().split(',')\n",
    "    for token in tokens:\n",
    "        clipVals.append(int(token))\n",
    "\n",
    "    numAlphas = len(alphas)\n",
    "    numApproaches = len(approachDict)\n",
    "    \n",
    "    biasModes = ['Free']\n",
    "    numDimSettings = len(numDims)\n",
    "    numClipSettings = len(clipVals)\n",
    "    numBiasModes = len(biasModes)\n",
    " \n",
    "    numLambdas = len(lambdas)\n",
    "    numParamSettings = numLambdas * numDimSettings * numClipSettings * numBiasModes\n",
    "    \n",
    "    paramSettings = list(itertools.product(lambdas, numDims, clipVals, biasModes))\n",
    "       \n",
    "#     ML100KCompleteTest = Datasets.ML100K('../')\n",
    "    ML100KCompleteTest = ML100K('../')\n",
    "    \n",
    "    allEstimates = numpy.zeros((numApproaches, numAlphas), dtype = numpy.longdouble)\n",
    "    \n",
    "    currMetric = None\n",
    "    if args.metric == 'MSE':\n",
    "        currMetric = Metrics.MSE\n",
    "    elif args.metric == 'MAE':\n",
    "        currMetric = Metrics.MAE\n",
    "    else:\n",
    "        print(\"Expt2: [ERR] Unrecognized metric\", args.metric)\n",
    "        sys.exit(0)\n",
    "        \n",
    "    print (\"Expt2: [LOG] Starting metric\", args.metric)\n",
    "        \n",
    "    def updateResults(val, approach, ind):\n",
    "        approachTuple = (approach, args.metric)\n",
    "        approachIndex = approachDict[approachTuple]\n",
    "        allEstimates[approachIndex, ind] = val\n",
    "            \n",
    "    print (\"Expt2: [LOG] Trial\", args.trial)\n",
    "    numpy.random.seed(args.seed + args.trial)\n",
    "    \n",
    "    outputFile = '../logs/expt2/'+str(args.seed)+'_'+str(args.trial)+'_'+args.metric+'_'\n",
    "    \n",
    "    for ind, alpha in enumerate(alphas):\n",
    "        print (\"Expt2: [LOG] Alpha:\", alpha)\n",
    "\n",
    "        partialObservations, goldPropensities = Propensity.PARTIAL_OBSERVE(ML100KCompleteTest, alpha, 0.05, verbose = False)\n",
    "       \n",
    "        flatObservations = numpy.ma.compressed(partialObservations) \n",
    "        observedHistogram = numpy.bincount(flatObservations, minlength = 6)[1:]\n",
    "        observedHistogram = observedHistogram.astype(numpy.longdouble) / \\\n",
    "                                observedHistogram.sum(dtype = numpy.longdouble)\n",
    "        print (\"Expt2: [LOG] Observed Marginals: \", observedHistogram)\n",
    "       \n",
    "        goldInvPropensities = numpy.reciprocal(goldPropensities)\n",
    "        \n",
    "        foldScores = numpy.zeros((numApproaches, 4, numParamSettings), dtype = numpy.longdouble)\n",
    "        foldTestScores = numpy.zeros((numApproaches, 4, numParamSettings), dtype = numpy.longdouble)\n",
    "        \n",
    "        observationIndices = numpy.ma.nonzero(partialObservations)\n",
    "        numObservations = numpy.ma.count(partialObservations)\n",
    " \n",
    "        shuffleIndices = numpy.random.permutation(numObservations)\n",
    "        fractionObservations = int(numObservations/4)\n",
    "        firstFold = shuffleIndices[:fractionObservations]\n",
    "        secondFold = shuffleIndices[fractionObservations:2*fractionObservations]\n",
    "        thirdFold = shuffleIndices[2*fractionObservations:3*fractionObservations]\n",
    "        fourthFold = shuffleIndices[3*fractionObservations:]\n",
    "        print (\"Expt2: [LOG] Split %d observations into folds. Fold sizes:\" % len(shuffleIndices),\\\n",
    "                        len(firstFold), len(secondFold), len(thirdFold), len(fourthFold))\n",
    "        \n",
    "        for fold in xrange(4):\n",
    "            print (\"Expt2: [LOG] Fold:\", fold)\n",
    "            trainObservations = numpy.ma.copy(partialObservations)\n",
    "            testObservations = numpy.ma.copy(partialObservations)\n",
    "\n",
    "            if fold == 0:\n",
    "                trainObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            elif fold == 1:\n",
    "                trainObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            elif fold == 2:\n",
    "                trainObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            elif fold == 3:\n",
    "                trainObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "\n",
    "                testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "                testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
    "                                        numpy.ma.masked\n",
    "            else:\n",
    "                print (\"Expt2: [ERR] #Folds not supported \", fold)\n",
    "                sys.exit(0)\n",
    "                   \n",
    "            #Get starting params by SVD\n",
    "            startFileName = outputFile + 'fold' + str(fold) + '_' + str(alpha) +'_init.pkl'\n",
    "            startTuple = None\n",
    "            if os.path.exists(startFileName):\n",
    "                g = open(startFileName, 'rb')\n",
    "                startTuple = pickle.load(g)\n",
    "                g.close()\n",
    "            else:\n",
    "                startTuple = INIT_PARAMS(trainObservations, 20)\n",
    "                g = open(startFileName, 'wb')\n",
    "                pickle.dump(startTuple, g, -1)\n",
    "                g.close()\n",
    "            \n",
    "            for approach in approaches:\n",
    "                print (\"Starting approach \", approach)\n",
    "                invP, normN = TRAIN_HELPER(approach, goldInvPropensities, None)\n",
    "                approachTuple = (approach, args.metric)\n",
    "                approachIndex = approachDict[approachTuple]\n",
    "                modelFileName = outputFile + 'fold' + str(fold) + '_' + str(alpha) +'_'+approach+'.pkl'\n",
    "                modelsPerLambda = None\n",
    "                if os.path.exists(modelFileName):\n",
    "                    g = open(modelFileName, 'rb')\n",
    "                    modelsPerLambda = pickle.load(g)\n",
    "                    g.close()\n",
    "                    print (\"Expt2: [LOG]\\t Loaded trained models for each lambda from \", modelFileName)\n",
    "                else:\n",
    "                    modelsPerLambda = Parallel(n_jobs = -1, verbose = 0)(delayed(MF_TRAIN)(l2Lambda, \n",
    "                                            trainObservations, invP, normN, args.metric, startTuple)\n",
    "                                            for l2Lambda in paramSettings)\n",
    "                    g = open(modelFileName, 'wb')\n",
    "                    pickle.dump(modelsPerLambda, g, -1)\n",
    "                    g.close()\n",
    "                    print (\"Expt2: [LOG]\\t Saved trained models for each lambda to \", modelFileName)\n",
    "\n",
    "                for lambdaIndex, eachModel in enumerate(modelsPerLambda):\n",
    "                    selectedBiasMode = paramSettings[lambdaIndex][3]\n",
    "                    selectedBias = True\n",
    "                    if selectedBiasMode == 'None':\n",
    "                        selectedBias = False\n",
    "\n",
    "                    predictedY = MF.PREDICTED_SCORES(eachModel[0], eachModel[1], \n",
    "                                                eachModel[2], eachModel[3], eachModel[4], use_bias = selectedBias)\n",
    "                    score = None\n",
    "                    if invP is not None:\n",
    "                        score = currMetric(testObservations, predictedY, 4.0*invP)\n",
    "                    else:\n",
    "                        score = currMetric(testObservations, predictedY, None)\n",
    "                        \n",
    "                    if normN == 'Vanilla':\n",
    "                        score = score[0]\n",
    "                    elif normN == 'SelfNormalized':\n",
    "                        score = score[1]\n",
    "                    elif normN == 'UserNormalized':\n",
    "                        score = score[2]\n",
    "                    elif normN == 'ItemNormalized':\n",
    "                        score = score[3]\n",
    "                    else:\n",
    "                        print (\"Expt2: [ERR] Normalization not supported for metric \", normN, args.metric)\n",
    "                        sys.exit(0)\n",
    "                    \n",
    "                    foldScores[approachIndex, fold, lambdaIndex] = score\n",
    "                    \n",
    "                    foldTestScore = currMetric(ML100KCompleteTest, predictedY, None)[0]\n",
    "                    foldTestScores[approachIndex, fold, lambdaIndex] = foldTestScore\n",
    "                    print (\"Expt2: [LOG] Lambda/NumDims: \", paramSettings[lambdaIndex],\n",
    "                                \"\\t Test Fold Score: \", score, \"\\t Test Set Score: \", foldTestScore)\n",
    "                \n",
    "                #Save foldScores and foldTestScores after each approach in each fold. Overwrite if needed.\n",
    "                scoresFile = outputFile + 'Alpha'+ str(alpha)+'_foldScores.pkl'\n",
    "                scoresData = (foldScores, foldTestScores)\n",
    "                g = open(scoresFile, 'wb')\n",
    "                pickle.dump(scoresData, g, -1)\n",
    "                g.close()\n",
    "                sys.stdout.flush()        \n",
    "        \n",
    "        eventualApproachParams = []\n",
    "        for approach in approaches:\n",
    "            invP, normN = TRAIN_HELPER(approach, goldInvPropensities, None)\n",
    "            approachTuple = (approach, args.metric)\n",
    "            approachIndex = approachDict[approachTuple]\n",
    "            approachScores = foldScores[approachIndex,:,:]\n",
    "            allFoldScores = approachScores.sum(axis = 0, dtype = numpy.longdouble)\n",
    "            bestLambdaIndex = numpy.argmin(allFoldScores)\n",
    "            bestLambda = paramSettings[bestLambdaIndex]\n",
    "            print (\"FINAL_TRAIN: [LOG] Retraining \", approach, \" Best lambda/numDims\", bestLambda    )\n",
    "            for everyLambdaIndex, everyLambda in enumerate(paramSettings):\n",
    "                print(\"FINAL_TRAIN: [DBG] AllFoldScores: \", approach, everyLambda, allFoldScores[everyLambdaIndex])\n",
    "            eventualApproachParams.append((approach,invP,normN,bestLambda))\n",
    "            \n",
    "        finalModels = None\n",
    "        finalModelFileName = outputFile + str(alpha) +'_finalmodels.pkl'\n",
    "        if os.path.exists(finalModelFileName):\n",
    "            g = open(finalModelFileName, 'rb')\n",
    "            finalModels = pickle.load(g)\n",
    "            g.close()\n",
    "            print (\"Expt2: [LOG]\\t Loaded trained final models from \", finalModelFileName)\n",
    "        else:\n",
    "            finalModels = Parallel(n_jobs = -1, verbose = 0)(delayed(FINAL_TRAIN)(approachTup, args.metric, \n",
    "                                        partialObservations, startTuple)\n",
    "                                        for approachTup in eventualApproachParams)\n",
    "            g = open(finalModelFileName, 'wb')\n",
    "            pickle.dump(finalModels, g, -1)\n",
    "            g.close()\n",
    "            print (\"Expt2: [LOG]\\t Saved trained final models to \", finalModelFileName)\n",
    "        \n",
    "        for approachID, approachTuple in enumerate(eventualApproachParams):\n",
    "            resultTuple = finalModels[approachID]\n",
    "            finalBiasMode = approachTuple[3][3]\n",
    "            finalBias = True\n",
    "            if finalBiasMode == 'None':\n",
    "                finalBias = False\n",
    "            predictedY = MF.PREDICTED_SCORES(resultTuple[0], resultTuple[1], \\\n",
    "                                resultTuple[2], resultTuple[3], resultTuple[4], use_bias = finalBias)\n",
    "\n",
    "            metricValue = currMetric(ML100KCompleteTest, predictedY, None)[0]\n",
    "            print (\"Expt2: [LOG] \", approachTuple[0], \"\\t Eventual result:\", metricValue)\n",
    "            sys.stdout.flush()\n",
    "            updateResults(metricValue, approachTuple[0], ind)    \n",
    "        \n",
    "        #Dump results after each alpha. Overwrite if needed.\n",
    "        outputData = (approaches, approachDict, alphas, allEstimates)\n",
    "        g = open(outputFile + args.estimators +'.pkl', 'wb')\n",
    "        pickle.dump(outputData, g, -1)\n",
    "        g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17015479",
   "metadata": {},
   "source": [
    "## Expt3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb27e1f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4981b90",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133fee5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae8d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
