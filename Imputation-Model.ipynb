{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a76157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "\n",
    "def ITEMWISE_METRICS(observed, observed_ratings, predicted_ratings,y,w):\n",
    "    delta = numpy.ma.subtract(predicted_ratings,observed_ratings)\n",
    "#     rectifiedDelta = numpy.square(delta)\n",
    "    rectifiedDelta = numpy.ma.abs(delta)\n",
    "    print(\"rectifiedDelta\")\n",
    "    print(rectifiedDelta)\n",
    "    \n",
    "    numUsers,numItems = numpy.shape(observed_ratings)\n",
    "    scale = numUsers * numItems\n",
    "    \n",
    "    #e^_{u,i} = w(r^_{u,i}-y)^2\n",
    "#     imputed_error = (numpy.square(numpy.ma.subtract(predicted_ratings,y))) * w \n",
    "    imputed_error = (numpy.ma.abs(numpy.ma.subtract(predicted_ratings,y))) * w \n",
    "    print(\"imputed_error\")\n",
    "    print(imputed_error)\n",
    "    \n",
    "    #OE1 = o_{u,i}e_{u,i}\n",
    "    observedError1 = numpy.ma.multiply(observed,rectifiedDelta)\n",
    "    print(\"observedError1\")\n",
    "    print(observedError1)\n",
    "    \n",
    "    #OE2 = (1-o{u,i})*e^_{u,i}\n",
    "    unobserved = numpy.ma.subtract(numpy.ones((numUsers,numItems)),observed)\n",
    "    observedError2 = numpy.ma.multiply(unobserved,imputed_error)\n",
    "    print(\"observedError2\")\n",
    "    print(observedError2)\n",
    "    \n",
    "    \n",
    "    totalObservedError = observedError1 + observedError2\n",
    "    cumulativeError = numpy.ma.sum(totalObservedError,dtype = numpy.longdouble)\n",
    "    print(\"cumulativeError\")\n",
    "    print(cumulativeError)\n",
    "    \n",
    "    vanillaMetric = cumulativeError / scale\n",
    "    print(\"vanillaMetric\")\n",
    "    print(vanillaMetric)\n",
    "    \n",
    "    return vanillaMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8cb96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAIN]\t True ratings:\n",
      "[[1 1 5]\n",
      " [1 1 5]]\n",
      "[MAIN]\t Predicted ratings:\n",
      "[[3 3 4]\n",
      " [3 3 4]]\n",
      "[MAIN]\t observed_ratings\n",
      "[[1. 1. 5.]\n",
      " [1. 1. 5.]]\n",
      "rectifiedDelta\n",
      "[[2. 2. 1.]\n",
      " [2. 2. 1.]]\n",
      "imputed_error\n",
      "[[1.5 1.5 0.5]\n",
      " [1.5 1.5 0.5]]\n",
      "observedError1\n",
      "[[2. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "observedError2\n",
      "[[0.  1.5 0.5]\n",
      " [1.5 1.5 0. ]]\n",
      "cumulativeError\n",
      "8.0\n",
      "vanillaMetric\n",
      "1.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    shape = (2,3)\n",
    "    true_ratings = [[1,1,5],\n",
    "                    [1,1,5]]\n",
    "    \n",
    "    predicted_ratings = [[3,3,4],\n",
    "                        [3,3,4]]\n",
    "    a = numpy.ma.array(true_ratings)\n",
    "    b = numpy.ma.array(predicted_ratings)\n",
    "    \n",
    "   \n",
    "    print (\"[MAIN]\\t True ratings:\")\n",
    "    print (a)\n",
    "    print (\"[MAIN]\\t Predicted ratings:\")\n",
    "    print (b)\n",
    "    \n",
    "    observed = [[1,0,0],\n",
    "                [0,0,1]]\n",
    "            \n",
    "    \n",
    "    \n",
    "    y = 4.5\n",
    "    w = 1\n",
    "    #observerd_ratings 这里不太确定\n",
    "    \n",
    "   \n",
    "    observed_ratings = numpy.ma.array(a, dtype = numpy.longdouble, copy = True, \n",
    "                             fill_value = 0, hard_mask = True)\n",
    "    print(\"[MAIN]\\t observed_ratings\")\n",
    "    print(observed_ratings)\n",
    "    ITEMWISE_METRICS(observed, observed_ratings,b,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ab9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e379cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "iter_count:  0 the loss: 0.6622632568496158\n",
      "iter_count:  1 the loss: 0.6563606807902649\n",
      "iter_count:  2 the loss: 0.5089810914144427\n",
      "iter_count:  3 the loss: 0.4758453164596926\n",
      "iter_count:  4 the loss: 0.4092588990737654\n",
      "iter_count:  5 the loss: 0.4796776861500707\n",
      "iter_count:  6 the loss: 0.4810206078420158\n",
      "iter_count:  7 the loss: 0.30552377435321276\n",
      "iter_count:  8 the loss: 0.31089477419652783\n",
      "iter_count:  9 the loss: 0.2835450907299296\n",
      "iter_count:  10 the loss: 0.2801180552472289\n",
      "iter_count:  11 the loss: 0.27366353733422405\n",
      "iter_count:  12 the loss: 0.2768398521693259\n",
      "iter_count:  13 the loss: 0.34693837058892185\n",
      "iter_count:  14 the loss: 0.2947385378368282\n",
      "iter_count:  15 the loss: 0.3039114346876849\n",
      "iter_count:  16 the loss: 0.323206827412185\n",
      "iter_count:  17 the loss: 0.32787762900037026\n",
      "iter_count:  18 the loss: 0.3089287527540661\n",
      "iter_count:  19 the loss: 0.3116731615208179\n",
      "iter_count:  20 the loss: 0.27639653702627337\n",
      "iter_count:  21 the loss: 0.2690182625787691\n",
      "iter_count:  22 the loss: 0.2778646361259427\n",
      "iter_count:  23 the loss: 0.27859792940757705\n",
      "iter_count:  24 the loss: 0.2730297925825695\n",
      "iter_count:  25 the loss: 0.26909233183786696\n",
      "iter_count:  26 the loss: 0.2743309855846866\n",
      "iter_count:  27 the loss: 0.27919723927679285\n",
      "iter_count:  28 the loss: 0.3028946028544467\n",
      "iter_count:  29 the loss: 0.2757216712311645\n",
      "iter_count:  30 the loss: 0.267418919642862\n",
      "iter_count:  31 the loss: 0.3043900867240933\n",
      "iter_count:  32 the loss: 0.4394243053655256\n",
      "iter_count:  33 the loss: 0.2795624175246075\n",
      "iter_count:  34 the loss: 0.28054494536190244\n",
      "iter_count:  35 the loss: 0.2854779897061551\n",
      "iter_count:  36 the loss: 0.2892688902612675\n",
      "iter_count:  37 the loss: 0.27040365520916576\n",
      "iter_count:  38 the loss: 0.2666219690800889\n",
      "iter_count:  39 the loss: 0.2672008050248782\n",
      "iter_count:  40 the loss: 0.2770117409243249\n",
      "iter_count:  41 the loss: 0.26999539925504584\n",
      "iter_count:  42 the loss: 0.2672384917381714\n",
      "iter_count:  43 the loss: 0.2700501352608048\n",
      "iter_count:  44 the loss: 0.30894876838219976\n",
      "iter_count:  45 the loss: 0.27298213612397376\n",
      "iter_count:  46 the loss: 0.2636484676032874\n",
      "iter_count:  47 the loss: 0.26344513182314916\n",
      "iter_count:  48 the loss: 0.26341666518421797\n",
      "iter_count:  49 the loss: 0.26468073618537197\n",
      "iter_count:  50 the loss: 0.28073412293179906\n",
      "iter_count:  51 the loss: 0.2741691427661629\n",
      "iter_count:  52 the loss: 0.2782621802907475\n",
      "iter_count:  53 the loss: 0.26156311787570113\n",
      "iter_count:  54 the loss: 0.2716985017343756\n",
      "iter_count:  55 the loss: 0.2651698209607821\n",
      "iter_count:  56 the loss: 0.2622054685389855\n",
      "iter_count:  57 the loss: 0.2631146999010584\n",
      "iter_count:  58 the loss: 0.2623925965825734\n",
      "iter_count:  59 the loss: 0.2636123993925101\n",
      "iter_count:  60 the loss: 0.26234453349472125\n",
      "iter_count:  61 the loss: 0.26264057110993333\n",
      "iter_count:  62 the loss: 0.26307574618643087\n",
      "iter_count:  63 the loss: 0.266377514235933\n",
      "iter_count:  64 the loss: 0.2783947237149486\n",
      "iter_count:  65 the loss: 0.28612281181964133\n",
      "iter_count:  66 the loss: 0.2849689460117693\n",
      "iter_count:  67 the loss: 0.27946312978461324\n",
      "iter_count:  68 the loss: 0.26261943617469796\n",
      "iter_count:  69 the loss: 0.26187074258670184\n",
      "iter_count:  70 the loss: 0.31975500322971917\n",
      "iter_count:  71 the loss: 0.39016627868526954\n",
      "iter_count:  72 the loss: 0.3719196058603673\n",
      "iter_count:  73 the loss: 0.4016980342148593\n",
      "iter_count:  74 the loss: 0.4580921727120547\n",
      "iter_count:  75 the loss: 0.37084578283192626\n",
      "iter_count:  76 the loss: 0.3045717735286614\n",
      "iter_count:  77 the loss: 0.2695845331122757\n",
      "iter_count:  78 the loss: 0.2728299318962738\n",
      "iter_count:  79 the loss: 0.25851663241135053\n",
      "iter_count:  80 the loss: 0.26305786878162035\n",
      "iter_count:  81 the loss: 0.270328427604184\n",
      "iter_count:  82 the loss: 0.2901684924245308\n",
      "iter_count:  83 the loss: 0.266494696810258\n",
      "iter_count:  84 the loss: 0.2742453805609838\n",
      "iter_count:  85 the loss: 0.2647437481909796\n",
      "iter_count:  86 the loss: 0.25998106487461325\n",
      "iter_count:  87 the loss: 0.25951757588605845\n",
      "iter_count:  88 the loss: 0.2576196737382044\n",
      "iter_count:  89 the loss: 0.27069043728731446\n",
      "iter_count:  90 the loss: 0.2861596908798885\n",
      "iter_count:  91 the loss: 0.2596166573359735\n",
      "iter_count:  92 the loss: 0.26613584596629886\n",
      "iter_count:  93 the loss: 0.27208781756335265\n",
      "iter_count:  94 the loss: 0.25542340503348265\n",
      "iter_count:  95 the loss: 0.2981394096757619\n",
      "iter_count:  96 the loss: 0.3033445246439708\n",
      "iter_count:  97 the loss: 0.3038262680861857\n",
      "iter_count:  98 the loss: 0.27068294901761164\n",
      "iter_count:  99 the loss: 0.3921693112947845\n",
      "iter_count:  100 the loss: 0.32201831465606134\n",
      "iter_count:  101 the loss: 0.2771703531884757\n",
      "iter_count:  102 the loss: 0.2826343040313868\n",
      "iter_count:  103 the loss: 0.2515348088891153\n",
      "iter_count:  104 the loss: 0.2512325825756202\n",
      "iter_count:  105 the loss: 0.28096776714375654\n",
      "iter_count:  106 the loss: 0.3221886145331281\n",
      "iter_count:  107 the loss: 0.2533188273144708\n",
      "iter_count:  108 the loss: 0.2553945626300966\n",
      "iter_count:  109 the loss: 0.3304164599093858\n",
      "iter_count:  110 the loss: 0.28788585998670846\n",
      "iter_count:  111 the loss: 0.2906100631957947\n",
      "iter_count:  112 the loss: 0.2628105209245335\n",
      "iter_count:  113 the loss: 0.35638152943169066\n",
      "iter_count:  114 the loss: 0.3454953357040563\n",
      "iter_count:  115 the loss: 0.2549537444140942\n",
      "iter_count:  116 the loss: 0.3566059181705442\n",
      "iter_count:  117 the loss: 0.2927580773339119\n",
      "iter_count:  118 the loss: 0.2778492548538025\n",
      "iter_count:  119 the loss: 0.2650365053133075\n",
      "iter_count:  120 the loss: 0.2640146327638009\n",
      "iter_count:  121 the loss: 0.2546603770382013\n",
      "iter_count:  122 the loss: 0.24946491634022275\n",
      "iter_count:  123 the loss: 0.24904136381644057\n",
      "iter_count:  124 the loss: 0.2482721133336378\n",
      "iter_count:  125 the loss: 0.2515753875457335\n",
      "iter_count:  126 the loss: 0.25300125269400947\n",
      "iter_count:  127 the loss: 0.24901734928616226\n",
      "iter_count:  128 the loss: 0.2630811547232908\n",
      "iter_count:  129 the loss: 0.25529308394307754\n",
      "iter_count:  130 the loss: 0.2516559663198812\n",
      "iter_count:  131 the loss: 0.2523033897443869\n",
      "iter_count:  132 the loss: 0.2593085573538127\n",
      "iter_count:  133 the loss: 0.2816625279917626\n",
      "iter_count:  134 the loss: 0.30813313148602783\n",
      "iter_count:  135 the loss: 0.28729453172863895\n",
      "iter_count:  136 the loss: 0.2632763706604306\n",
      "iter_count:  137 the loss: 0.25116535467216455\n",
      "iter_count:  138 the loss: 0.25371898361907635\n",
      "iter_count:  139 the loss: 0.2573652069112122\n",
      "iter_count:  140 the loss: 0.25074431164119154\n",
      "iter_count:  141 the loss: 0.25149287120010616\n",
      "iter_count:  142 the loss: 0.24822229212280877\n",
      "iter_count:  143 the loss: 0.2503401444187745\n",
      "iter_count:  144 the loss: 0.25638418822576853\n",
      "iter_count:  145 the loss: 0.249282617926793\n",
      "iter_count:  146 the loss: 0.24666922189582788\n",
      "iter_count:  147 the loss: 0.2465784357852782\n",
      "iter_count:  148 the loss: 0.3395580922238608\n",
      "iter_count:  149 the loss: 0.3065741979856648\n",
      "iter_count:  150 the loss: 0.2884403654756473\n",
      "iter_count:  151 the loss: 0.25423802700787185\n",
      "iter_count:  152 the loss: 0.24631959389239785\n",
      "iter_count:  153 the loss: 0.24599670193035353\n",
      "iter_count:  154 the loss: 0.2753851651262291\n",
      "iter_count:  155 the loss: 0.39098132702615823\n",
      "iter_count:  156 the loss: 0.35091194204855225\n",
      "iter_count:  157 the loss: 0.3661408892242742\n",
      "iter_count:  158 the loss: 0.38023815572925546\n",
      "iter_count:  159 the loss: 0.37614530499822724\n",
      "iter_count:  160 the loss: 0.3171457679256827\n",
      "iter_count:  161 the loss: 0.3167821181244409\n",
      "iter_count:  162 the loss: 0.3190519235663628\n",
      "iter_count:  163 the loss: 0.2630330631079773\n",
      "iter_count:  164 the loss: 0.24770857472939833\n",
      "iter_count:  165 the loss: 0.2501526985319508\n",
      "iter_count:  166 the loss: 0.25996888234136495\n",
      "iter_count:  167 the loss: 0.26558801551505756\n",
      "iter_count:  168 the loss: 0.24555751791500094\n",
      "iter_count:  169 the loss: 0.24617878866562487\n",
      "iter_count:  170 the loss: 0.246641750120793\n",
      "iter_count:  171 the loss: 0.2440478299385542\n",
      "iter_count:  172 the loss: 0.27128559630351873\n",
      "iter_count:  173 the loss: 0.24521506171664104\n",
      "iter_count:  174 the loss: 0.2446160265287837\n",
      "iter_count:  175 the loss: 0.2413709056792221\n",
      "iter_count:  176 the loss: 0.24092047731799737\n",
      "iter_count:  177 the loss: 0.24075479528717708\n",
      "iter_count:  178 the loss: 0.24594117086162676\n",
      "iter_count:  179 the loss: 0.24763187925191132\n",
      "iter_count:  180 the loss: 0.31396126060236823\n",
      "iter_count:  181 the loss: 0.27874353958608095\n",
      "iter_count:  182 the loss: 0.2867093173781363\n",
      "iter_count:  183 the loss: 0.2821600458796014\n",
      "iter_count:  184 the loss: 0.24134354899076493\n",
      "iter_count:  185 the loss: 0.24344117704749807\n",
      "iter_count:  186 the loss: 0.24037546204956092\n",
      "iter_count:  187 the loss: 0.23938775746853402\n",
      "iter_count:  188 the loss: 0.23983745598775794\n",
      "iter_count:  189 the loss: 0.23972896059427495\n",
      "iter_count:  190 the loss: 0.24964502378837278\n",
      "iter_count:  191 the loss: 0.2488090869000702\n",
      "iter_count:  192 the loss: 0.25031981486650595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  193 the loss: 0.2729370671888877\n",
      "iter_count:  194 the loss: 0.2845245609088388\n",
      "iter_count:  195 the loss: 0.26084865510245825\n",
      "iter_count:  196 the loss: 0.29819110436406854\n",
      "iter_count:  197 the loss: 0.30214746543913107\n",
      "iter_count:  198 the loss: 0.2568570777713006\n",
      "iter_count:  199 the loss: 0.25832948739986644\n",
      "iter_count:  200 the loss: 0.267105145844704\n",
      "iter_count:  201 the loss: 0.2752064433470574\n",
      "iter_count:  202 the loss: 0.39151179604521424\n",
      "iter_count:  203 the loss: 0.39466033322523925\n",
      "iter_count:  204 the loss: 0.3145571315501955\n",
      "iter_count:  205 the loss: 0.2843051925913901\n",
      "iter_count:  206 the loss: 0.24816705463915803\n",
      "iter_count:  207 the loss: 0.24543859244947405\n",
      "iter_count:  208 the loss: 0.2842283814157143\n",
      "iter_count:  209 the loss: 0.315641960997712\n",
      "iter_count:  210 the loss: 0.26440853053268465\n",
      "iter_count:  211 the loss: 0.24051638571260603\n",
      "iter_count:  212 the loss: 0.24808494084106372\n",
      "iter_count:  213 the loss: 0.23437209562213346\n",
      "iter_count:  214 the loss: 0.23466266829763413\n",
      "iter_count:  215 the loss: 0.24828237385144528\n",
      "iter_count:  216 the loss: 0.28206551707754934\n",
      "iter_count:  217 the loss: 0.2941487178227541\n",
      "iter_count:  218 the loss: 0.3182068398497429\n",
      "iter_count:  219 the loss: 0.3300191392314391\n",
      "iter_count:  220 the loss: 0.23290730460102027\n",
      "iter_count:  221 the loss: 0.2329608289173254\n",
      "iter_count:  222 the loss: 0.23809720687936398\n",
      "iter_count:  223 the loss: 0.2339048947290386\n",
      "iter_count:  224 the loss: 0.24809540016305612\n",
      "iter_count:  225 the loss: 0.24711886380229892\n",
      "iter_count:  226 the loss: 0.238018519959974\n",
      "iter_count:  227 the loss: 0.23285376411493885\n",
      "iter_count:  228 the loss: 0.2326610625918345\n",
      "iter_count:  229 the loss: 0.2416202261156308\n",
      "iter_count:  230 the loss: 0.23317314659338903\n",
      "iter_count:  231 the loss: 0.23470098967154676\n",
      "iter_count:  232 the loss: 0.23295682370716908\n",
      "iter_count:  233 the loss: 0.23368024983056326\n",
      "iter_count:  234 the loss: 0.2370553998238712\n",
      "iter_count:  235 the loss: 0.2573520744571454\n",
      "iter_count:  236 the loss: 0.24222482385096816\n",
      "iter_count:  237 the loss: 0.23543367822811478\n",
      "iter_count:  238 the loss: 0.2327977130370259\n",
      "iter_count:  239 the loss: 0.23069146472002253\n",
      "iter_count:  240 the loss: 0.2381079559940535\n",
      "iter_count:  241 the loss: 0.2582644520630893\n",
      "iter_count:  242 the loss: 0.2799310928384161\n",
      "iter_count:  243 the loss: 0.2561908203134167\n",
      "iter_count:  244 the loss: 0.2802856082279466\n",
      "iter_count:  245 the loss: 0.31308269582657755\n",
      "iter_count:  246 the loss: 0.3218108991124724\n",
      "iter_count:  247 the loss: 0.2385895106822499\n",
      "iter_count:  248 the loss: 0.24005299526292034\n",
      "iter_count:  249 the loss: 0.26378941825489555\n",
      "iter_count:  250 the loss: 0.2447509776520742\n",
      "iter_count:  251 the loss: 0.24603230567288528\n",
      "iter_count:  252 the loss: 0.22856710647452408\n",
      "iter_count:  253 the loss: 0.23196292549663444\n",
      "iter_count:  254 the loss: 0.23525611876913366\n",
      "iter_count:  255 the loss: 0.22832511014602078\n",
      "iter_count:  256 the loss: 0.22876739097198065\n",
      "iter_count:  257 the loss: 0.2276107051581678\n",
      "iter_count:  258 the loss: 0.2279770769760486\n",
      "iter_count:  259 the loss: 0.22751661934895823\n",
      "iter_count:  260 the loss: 0.2304880101073338\n",
      "iter_count:  261 the loss: 0.23478574100534658\n",
      "iter_count:  262 the loss: 0.23977006112809338\n",
      "iter_count:  263 the loss: 0.32923999278100274\n",
      "iter_count:  264 the loss: 0.40432325147773934\n",
      "iter_count:  265 the loss: 0.2607653722036112\n",
      "iter_count:  266 the loss: 0.25037938908190627\n",
      "iter_count:  267 the loss: 0.23245798609977503\n",
      "iter_count:  268 the loss: 0.2280133200138869\n",
      "iter_count:  269 the loss: 0.23318110704141062\n",
      "iter_count:  270 the loss: 0.252724789693339\n",
      "iter_count:  271 the loss: 0.24096712820517827\n",
      "iter_count:  272 the loss: 0.24189419534332068\n",
      "iter_count:  273 the loss: 0.22742459494454834\n",
      "iter_count:  274 the loss: 0.2369972971810603\n",
      "iter_count:  275 the loss: 0.23463174878458226\n",
      "iter_count:  276 the loss: 0.24734996325045736\n",
      "iter_count:  277 the loss: 0.25681175646911636\n",
      "iter_count:  278 the loss: 0.2698732077733088\n",
      "iter_count:  279 the loss: 0.25006255835201485\n",
      "iter_count:  280 the loss: 0.22876937085214594\n",
      "iter_count:  281 the loss: 0.22580068737029718\n",
      "iter_count:  282 the loss: 0.2261633349773136\n",
      "iter_count:  283 the loss: 0.2823241856795149\n",
      "iter_count:  284 the loss: 0.32236577066297756\n",
      "iter_count:  285 the loss: 0.33671707095665965\n",
      "iter_count:  286 the loss: 0.2743294998313893\n",
      "iter_count:  287 the loss: 0.23811744911520896\n",
      "iter_count:  288 the loss: 0.2332611995807562\n",
      "iter_count:  289 the loss: 0.22596985318410429\n",
      "iter_count:  290 the loss: 0.22451799581943938\n",
      "iter_count:  291 the loss: 0.22488314123876058\n",
      "iter_count:  292 the loss: 0.22528819696062743\n",
      "iter_count:  293 the loss: 0.26350785773193336\n",
      "iter_count:  294 the loss: 0.2708950406717667\n",
      "iter_count:  295 the loss: 0.3134149198369168\n",
      "iter_count:  296 the loss: 0.35104404167928427\n",
      "iter_count:  297 the loss: 0.3255650960503331\n",
      "iter_count:  298 the loss: 0.3301287427522283\n",
      "iter_count:  299 the loss: 0.3489465372193628\n",
      "iter_count:  300 the loss: 0.37193847657225165\n",
      "iter_count:  301 the loss: 0.39785070731666333\n",
      "iter_count:  302 the loss: 0.2570685706280378\n",
      "iter_count:  303 the loss: 0.2277712046116409\n",
      "iter_count:  304 the loss: 0.2717000185746501\n",
      "iter_count:  305 the loss: 0.23722185169342525\n",
      "iter_count:  306 the loss: 0.3341662082653283\n",
      "iter_count:  307 the loss: 0.2773128001490086\n",
      "iter_count:  308 the loss: 0.24540049901713287\n",
      "iter_count:  309 the loss: 0.24386337719888534\n",
      "iter_count:  310 the loss: 0.25297093968312556\n",
      "iter_count:  311 the loss: 0.25832286716631514\n",
      "iter_count:  312 the loss: 0.2247998043078321\n",
      "iter_count:  313 the loss: 0.22626530905555356\n",
      "iter_count:  314 the loss: 0.2278983293881998\n",
      "iter_count:  315 the loss: 0.24333709594991795\n",
      "iter_count:  316 the loss: 0.24218461834561647\n",
      "iter_count:  317 the loss: 0.2255006601776387\n",
      "iter_count:  318 the loss: 0.2250011981599648\n",
      "iter_count:  319 the loss: 0.23177971904793\n",
      "iter_count:  320 the loss: 0.2307374774859861\n",
      "iter_count:  321 the loss: 0.31621868681558357\n",
      "iter_count:  322 the loss: 0.2926715774808941\n",
      "iter_count:  323 the loss: 0.27776139314076503\n",
      "iter_count:  324 the loss: 0.22371801970829214\n",
      "iter_count:  325 the loss: 0.2263279982717342\n",
      "iter_count:  326 the loss: 0.2857120330681283\n",
      "iter_count:  327 the loss: 0.2961462342130985\n",
      "iter_count:  328 the loss: 0.28159718767365904\n",
      "iter_count:  329 the loss: 0.26846102153465995\n",
      "iter_count:  330 the loss: 0.2854332919982255\n",
      "iter_count:  331 the loss: 0.24410350840089134\n",
      "iter_count:  332 the loss: 0.22401964618756331\n",
      "iter_count:  333 the loss: 0.2526063244940784\n",
      "iter_count:  334 the loss: 0.28494158024684424\n",
      "iter_count:  335 the loss: 0.2773861759452119\n",
      "iter_count:  336 the loss: 0.2833229284633808\n",
      "iter_count:  337 the loss: 0.2698398675572727\n",
      "iter_count:  338 the loss: 0.2544868529429407\n",
      "iter_count:  339 the loss: 0.24597078276325665\n",
      "iter_count:  340 the loss: 0.2585939055823315\n",
      "iter_count:  341 the loss: 0.26186259932608397\n",
      "iter_count:  342 the loss: 0.24152886284979833\n",
      "iter_count:  343 the loss: 0.2659755160917146\n",
      "iter_count:  344 the loss: 0.25307856387356636\n",
      "iter_count:  345 the loss: 0.2755274642851846\n",
      "iter_count:  346 the loss: 0.3109637873459797\n",
      "iter_count:  347 the loss: 0.2761638211579579\n",
      "iter_count:  348 the loss: 0.2501552628523845\n",
      "iter_count:  349 the loss: 0.23744224994572122\n",
      "iter_count:  350 the loss: 0.23017115738605307\n",
      "iter_count:  351 the loss: 0.2497690925477025\n",
      "iter_count:  352 the loss: 0.2390544545039102\n",
      "iter_count:  353 the loss: 0.2235469764882994\n",
      "iter_count:  354 the loss: 0.2268019301200084\n",
      "iter_count:  355 the loss: 0.24133138374331964\n",
      "iter_count:  356 the loss: 0.24197898406252005\n",
      "iter_count:  357 the loss: 0.23180561834069685\n",
      "iter_count:  358 the loss: 0.22533000487380736\n",
      "iter_count:  359 the loss: 0.223600636235409\n",
      "iter_count:  360 the loss: 0.23790781245053785\n",
      "iter_count:  361 the loss: 0.23077407247016207\n",
      "iter_count:  362 the loss: 0.25533690089073846\n",
      "iter_count:  363 the loss: 0.23774844216329252\n",
      "iter_count:  364 the loss: 0.2540138568905987\n",
      "iter_count:  365 the loss: 0.2490010778149203\n",
      "iter_count:  366 the loss: 0.24776557207789907\n",
      "iter_count:  367 the loss: 0.22481516715697225\n",
      "iter_count:  368 the loss: 0.25113616040134873\n",
      "iter_count:  369 the loss: 0.231412579756498\n",
      "iter_count:  370 the loss: 0.23313015592729133\n",
      "iter_count:  371 the loss: 0.2996769143191934\n",
      "iter_count:  372 the loss: 0.2883744009836007\n",
      "iter_count:  373 the loss: 0.32791154100146874\n",
      "iter_count:  374 the loss: 0.24702193881657164\n",
      "iter_count:  375 the loss: 0.2876608810939225\n",
      "iter_count:  376 the loss: 0.2501585439514044\n",
      "iter_count:  377 the loss: 0.30671470150181135\n",
      "iter_count:  378 the loss: 0.2557210464183313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  379 the loss: 0.22436977851611542\n",
      "iter_count:  380 the loss: 0.23461032832225803\n",
      "iter_count:  381 the loss: 0.29780812493102066\n",
      "iter_count:  382 the loss: 0.25069069043211223\n",
      "iter_count:  383 the loss: 0.232854435055193\n",
      "iter_count:  384 the loss: 0.2321282191063687\n",
      "iter_count:  385 the loss: 0.24176401911724915\n",
      "iter_count:  386 the loss: 0.2256692818575183\n",
      "iter_count:  387 the loss: 0.22985050794632145\n",
      "iter_count:  388 the loss: 0.24830099126980493\n",
      "iter_count:  389 the loss: 0.26253639922293026\n",
      "iter_count:  390 the loss: 0.2389723738427056\n",
      "iter_count:  391 the loss: 0.2249862160465973\n",
      "iter_count:  392 the loss: 0.232210883528827\n",
      "iter_count:  393 the loss: 0.23764314815636395\n",
      "iter_count:  394 the loss: 0.22364814796413796\n",
      "iter_count:  395 the loss: 0.2226875596734035\n",
      "iter_count:  396 the loss: 0.2606619966637668\n",
      "iter_count:  397 the loss: 0.2360935570136853\n",
      "iter_count:  398 the loss: 0.24244782982821644\n",
      "iter_count:  399 the loss: 0.22430492492029708\n",
      "iter_count:  400 the loss: 0.2295088923875349\n",
      "iter_count:  401 the loss: 0.22663835020545456\n",
      "iter_count:  402 the loss: 0.22092635757997564\n",
      "iter_count:  403 the loss: 0.22221134596275335\n",
      "iter_count:  404 the loss: 0.22813629649635303\n",
      "iter_count:  405 the loss: 0.22098685923126535\n",
      "iter_count:  406 the loss: 0.22844411627453046\n",
      "iter_count:  407 the loss: 0.2221528780817759\n",
      "iter_count:  408 the loss: 0.22148298657868395\n",
      "iter_count:  409 the loss: 0.22680746987367464\n",
      "iter_count:  410 the loss: 0.24431775790203658\n",
      "iter_count:  411 the loss: 0.26523247156918567\n",
      "iter_count:  412 the loss: 0.24302047735272947\n",
      "iter_count:  413 the loss: 0.2651261963311251\n",
      "iter_count:  414 the loss: 0.2565476422835523\n",
      "iter_count:  415 the loss: 0.2495416351892965\n",
      "iter_count:  416 the loss: 0.28154614968668784\n",
      "iter_count:  417 the loss: 0.3106049199756127\n",
      "iter_count:  418 the loss: 0.25256571930062527\n",
      "iter_count:  419 the loss: 0.2203854579822568\n",
      "iter_count:  420 the loss: 0.23080466865239432\n",
      "iter_count:  421 the loss: 0.23869390926705103\n",
      "iter_count:  422 the loss: 0.21941517008751948\n",
      "iter_count:  423 the loss: 0.21940183131965577\n",
      "iter_count:  424 the loss: 0.22084746021778995\n",
      "iter_count:  425 the loss: 0.22107822750400166\n",
      "iter_count:  426 the loss: 0.2195898275504395\n",
      "iter_count:  427 the loss: 0.21948357998603157\n",
      "iter_count:  428 the loss: 0.22325219003439042\n",
      "iter_count:  429 the loss: 0.21969142991357765\n",
      "iter_count:  430 the loss: 0.2208250581464353\n",
      "iter_count:  431 the loss: 0.22241202857312786\n",
      "iter_count:  432 the loss: 0.22400937213738564\n",
      "iter_count:  433 the loss: 0.30136745284521516\n",
      "iter_count:  434 the loss: 0.25668486763653414\n",
      "iter_count:  435 the loss: 0.25248829277431534\n",
      "iter_count:  436 the loss: 0.22660287996971695\n",
      "iter_count:  437 the loss: 0.22788066096601167\n",
      "iter_count:  438 the loss: 0.222586400227866\n",
      "iter_count:  439 the loss: 0.23189520634622146\n",
      "iter_count:  440 the loss: 0.2333528479889207\n",
      "iter_count:  441 the loss: 0.24203648047230494\n",
      "iter_count:  442 the loss: 0.27753191448404013\n",
      "iter_count:  443 the loss: 0.2652649589934397\n",
      "iter_count:  444 the loss: 0.27452813164685114\n",
      "iter_count:  445 the loss: 0.2775561661782584\n",
      "iter_count:  446 the loss: 0.3057231557145273\n",
      "iter_count:  447 the loss: 0.30149192358909427\n",
      "iter_count:  448 the loss: 0.31018348032715637\n",
      "iter_count:  449 the loss: 0.264714320481093\n",
      "iter_count:  450 the loss: 0.26548531310555157\n",
      "iter_count:  451 the loss: 0.2330845686853592\n",
      "iter_count:  452 the loss: 0.2191531446739534\n",
      "iter_count:  453 the loss: 0.22120611766607962\n",
      "iter_count:  454 the loss: 0.22429750894271303\n",
      "iter_count:  455 the loss: 0.21926340736793407\n",
      "iter_count:  456 the loss: 0.25306027403909065\n",
      "iter_count:  457 the loss: 0.2971650805523884\n",
      "iter_count:  458 the loss: 0.26718835405208946\n",
      "iter_count:  459 the loss: 0.24910967364819453\n",
      "iter_count:  460 the loss: 0.22429819943989243\n",
      "iter_count:  461 the loss: 0.22003245602182123\n",
      "iter_count:  462 the loss: 0.22017863418081549\n",
      "iter_count:  463 the loss: 0.22648957272433937\n",
      "iter_count:  464 the loss: 0.27195448679631273\n",
      "iter_count:  465 the loss: 0.23581794659775557\n",
      "iter_count:  466 the loss: 0.22604845601046195\n",
      "iter_count:  467 the loss: 0.23722309726497412\n",
      "iter_count:  468 the loss: 0.2833789520896733\n",
      "iter_count:  469 the loss: 0.24244990720738183\n",
      "iter_count:  470 the loss: 0.2601670234048459\n",
      "iter_count:  471 the loss: 0.2479164772908241\n",
      "iter_count:  472 the loss: 0.2644446352780063\n",
      "iter_count:  473 the loss: 0.2315324451308668\n",
      "iter_count:  474 the loss: 0.21720072017246067\n",
      "iter_count:  475 the loss: 0.22801161688002597\n",
      "iter_count:  476 the loss: 0.22362404369826752\n",
      "iter_count:  477 the loss: 0.21970316180724073\n",
      "iter_count:  478 the loss: 0.21673067324828169\n",
      "iter_count:  479 the loss: 0.21693886808941246\n",
      "iter_count:  480 the loss: 0.22356651279701367\n",
      "iter_count:  481 the loss: 0.24263894717434295\n",
      "iter_count:  482 the loss: 0.22761639079500454\n",
      "iter_count:  483 the loss: 0.22972546121705759\n",
      "iter_count:  484 the loss: 0.21904014056752405\n",
      "iter_count:  485 the loss: 0.21779516335937496\n",
      "iter_count:  486 the loss: 0.21827489802989225\n",
      "iter_count:  487 the loss: 0.21851975577550461\n",
      "iter_count:  488 the loss: 0.24937095102351334\n",
      "iter_count:  489 the loss: 0.2419869793751753\n",
      "iter_count:  490 the loss: 0.23087664044737097\n",
      "iter_count:  491 the loss: 0.25507767576968465\n",
      "iter_count:  492 the loss: 0.21796502015391875\n",
      "iter_count:  493 the loss: 0.216412459077789\n",
      "iter_count:  494 the loss: 0.2180019936675095\n",
      "iter_count:  495 the loss: 0.2176304517054132\n",
      "iter_count:  496 the loss: 0.21663509334422673\n",
      "iter_count:  497 the loss: 0.21936866906895222\n",
      "iter_count:  498 the loss: 0.23489784046429216\n",
      "iter_count:  499 the loss: 0.24895076018729126\n",
      "iter_count:  500 the loss: 0.2793342813888986\n",
      "iter_count:  501 the loss: 0.3027038184555888\n",
      "iter_count:  502 the loss: 0.2622432425982453\n",
      "iter_count:  503 the loss: 0.2210561034469501\n",
      "iter_count:  504 the loss: 0.21846732958155046\n",
      "iter_count:  505 the loss: 0.2344866000166336\n",
      "iter_count:  506 the loss: 0.24352760127426726\n",
      "iter_count:  507 the loss: 0.22054689704310465\n",
      "iter_count:  508 the loss: 0.21459882768943817\n",
      "iter_count:  509 the loss: 0.22527915298751863\n",
      "iter_count:  510 the loss: 0.22791697484928014\n",
      "iter_count:  511 the loss: 0.2426969345616402\n",
      "iter_count:  512 the loss: 0.2228844428728489\n",
      "iter_count:  513 the loss: 0.21408929305189292\n",
      "iter_count:  514 the loss: 0.21837387115945786\n",
      "iter_count:  515 the loss: 0.2245295346933287\n",
      "iter_count:  516 the loss: 0.2754767622124009\n",
      "iter_count:  517 the loss: 0.2924443056937741\n",
      "iter_count:  518 the loss: 0.2200099172600904\n",
      "iter_count:  519 the loss: 0.23854043236522612\n",
      "iter_count:  520 the loss: 0.23853521838318714\n",
      "iter_count:  521 the loss: 0.22497791227256791\n",
      "iter_count:  522 the loss: 0.22012717322989198\n",
      "iter_count:  523 the loss: 0.2822617179470931\n",
      "iter_count:  524 the loss: 0.29627813588692253\n",
      "iter_count:  525 the loss: 0.25263297680778823\n",
      "iter_count:  526 the loss: 0.21978857772953417\n",
      "iter_count:  527 the loss: 0.2127104516599933\n",
      "iter_count:  528 the loss: 0.213076287858856\n",
      "iter_count:  529 the loss: 0.21269353973833932\n",
      "iter_count:  530 the loss: 0.21718708522286845\n",
      "iter_count:  531 the loss: 0.21324680036159316\n",
      "iter_count:  532 the loss: 0.21437326315272767\n",
      "iter_count:  533 the loss: 0.22577938949963258\n",
      "iter_count:  534 the loss: 0.23541212366781944\n",
      "iter_count:  535 the loss: 0.25351844881956914\n",
      "iter_count:  536 the loss: 0.2954973520150912\n",
      "iter_count:  537 the loss: 0.25594063051179805\n",
      "iter_count:  538 the loss: 0.2731907529706147\n",
      "iter_count:  539 the loss: 0.2428212522476126\n",
      "iter_count:  540 the loss: 0.23711301487323802\n",
      "iter_count:  541 the loss: 0.21299270124614783\n",
      "iter_count:  542 the loss: 0.2695740283511342\n",
      "iter_count:  543 the loss: 0.2692333503303586\n",
      "iter_count:  544 the loss: 0.21965116632940834\n",
      "iter_count:  545 the loss: 0.21524722557599482\n",
      "iter_count:  546 the loss: 0.21334216503857906\n",
      "iter_count:  547 the loss: 0.21566156516852888\n",
      "iter_count:  548 the loss: 0.22156087130215363\n",
      "iter_count:  549 the loss: 0.22400155188044168\n",
      "iter_count:  550 the loss: 0.22043233461418818\n",
      "iter_count:  551 the loss: 0.2243001923498197\n",
      "iter_count:  552 the loss: 0.21574979077750647\n",
      "iter_count:  553 the loss: 0.22251852154817142\n",
      "iter_count:  554 the loss: 0.23503164553294303\n",
      "iter_count:  555 the loss: 0.24946231980149675\n",
      "iter_count:  556 the loss: 0.22380760084904947\n",
      "iter_count:  557 the loss: 0.21477313778158585\n",
      "iter_count:  558 the loss: 0.21358855079353833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  559 the loss: 0.22759020999144786\n",
      "iter_count:  560 the loss: 0.24007645351987467\n",
      "iter_count:  561 the loss: 0.25670950141697335\n",
      "iter_count:  562 the loss: 0.23633598866786243\n",
      "iter_count:  563 the loss: 0.21373375982392212\n",
      "iter_count:  564 the loss: 0.21586692918568498\n",
      "iter_count:  565 the loss: 0.2211659254188719\n",
      "iter_count:  566 the loss: 0.22426028373656684\n",
      "iter_count:  567 the loss: 0.21896548417090717\n",
      "iter_count:  568 the loss: 0.21458191100111004\n",
      "iter_count:  569 the loss: 0.2135588555924185\n",
      "iter_count:  570 the loss: 0.2145348791383502\n",
      "iter_count:  571 the loss: 0.22786491625395072\n",
      "iter_count:  572 the loss: 0.21888407402012855\n",
      "iter_count:  573 the loss: 0.23398233791095518\n",
      "iter_count:  574 the loss: 0.2271943617299652\n",
      "iter_count:  575 the loss: 0.24999756771630918\n",
      "iter_count:  576 the loss: 0.24383444260224688\n",
      "iter_count:  577 the loss: 0.22457858954437693\n",
      "iter_count:  578 the loss: 0.2311839009037287\n",
      "iter_count:  579 the loss: 0.25458624523222495\n",
      "iter_count:  580 the loss: 0.2334833781967078\n",
      "iter_count:  581 the loss: 0.2708839494272512\n",
      "iter_count:  582 the loss: 0.27531132240245443\n",
      "iter_count:  583 the loss: 0.3143593089196458\n",
      "iter_count:  584 the loss: 0.21118479805256463\n",
      "iter_count:  585 the loss: 0.21195237861496002\n",
      "iter_count:  586 the loss: 0.21919600971844366\n",
      "iter_count:  587 the loss: 0.21356135208170998\n",
      "iter_count:  588 the loss: 0.2156810714151751\n",
      "iter_count:  589 the loss: 0.22255680979254747\n",
      "iter_count:  590 the loss: 0.24817457014956948\n",
      "iter_count:  591 the loss: 0.2233426617193372\n",
      "iter_count:  592 the loss: 0.23738238959636682\n",
      "iter_count:  593 the loss: 0.25292914855555937\n",
      "iter_count:  594 the loss: 0.26477958469721025\n",
      "iter_count:  595 the loss: 0.24526621149440353\n",
      "iter_count:  596 the loss: 0.2632296220499226\n",
      "iter_count:  597 the loss: 0.2632958774994179\n",
      "iter_count:  598 the loss: 0.25399255899226564\n",
      "iter_count:  599 the loss: 0.21171486910547618\n",
      "iter_count:  600 the loss: 0.2131525663439902\n",
      "iter_count:  601 the loss: 0.21295566865224538\n",
      "iter_count:  602 the loss: 0.22373293829806565\n",
      "iter_count:  603 the loss: 0.26496740969144467\n",
      "iter_count:  604 the loss: 0.24614811510069382\n",
      "iter_count:  605 the loss: 0.24130564053512013\n",
      "iter_count:  606 the loss: 0.2140080619117623\n",
      "iter_count:  607 the loss: 0.219625044943466\n",
      "iter_count:  608 the loss: 0.2632141026594394\n",
      "iter_count:  609 the loss: 0.2837338755751371\n",
      "iter_count:  610 the loss: 0.24256549827075516\n",
      "iter_count:  611 the loss: 0.21970001121846094\n",
      "iter_count:  612 the loss: 0.22140660425576814\n",
      "iter_count:  613 the loss: 0.21442382733167736\n",
      "iter_count:  614 the loss: 0.2225139672286586\n",
      "iter_count:  615 the loss: 0.22012430622026788\n",
      "iter_count:  616 the loss: 0.2302612808851328\n",
      "iter_count:  617 the loss: 0.2337630835341308\n",
      "iter_count:  618 the loss: 0.21833169349137913\n",
      "iter_count:  619 the loss: 0.21580227632521767\n",
      "iter_count:  620 the loss: 0.214293323287721\n",
      "iter_count:  621 the loss: 0.21859033761015847\n",
      "iter_count:  622 the loss: 0.2132285977322529\n",
      "iter_count:  623 the loss: 0.2242708510564009\n",
      "iter_count:  624 the loss: 0.21780500549713838\n",
      "iter_count:  625 the loss: 0.22823720010599233\n",
      "iter_count:  626 the loss: 0.21282063715637092\n",
      "iter_count:  627 the loss: 0.21203194462792968\n",
      "iter_count:  628 the loss: 0.22148151300823946\n",
      "iter_count:  629 the loss: 0.2122172679139637\n",
      "iter_count:  630 the loss: 0.23691246989076098\n",
      "iter_count:  631 the loss: 0.2523804172511851\n",
      "iter_count:  632 the loss: 0.2733940034820568\n",
      "iter_count:  633 the loss: 0.24774469106518512\n",
      "iter_count:  634 the loss: 0.27798232073141393\n",
      "iter_count:  635 the loss: 0.2619538751340984\n",
      "iter_count:  636 the loss: 0.24143501201726253\n",
      "iter_count:  637 the loss: 0.23932182266484262\n",
      "iter_count:  638 the loss: 0.22015445973181824\n",
      "iter_count:  639 the loss: 0.21367633676474743\n",
      "iter_count:  640 the loss: 0.211180824880054\n",
      "iter_count:  641 the loss: 0.2411041721169979\n",
      "iter_count:  642 the loss: 0.2561834048994985\n",
      "iter_count:  643 the loss: 0.28924153299796795\n",
      "iter_count:  644 the loss: 0.2805905749834338\n",
      "iter_count:  645 the loss: 0.2105360144768032\n",
      "iter_count:  646 the loss: 0.210513528821333\n",
      "iter_count:  647 the loss: 0.2125466012916599\n",
      "iter_count:  648 the loss: 0.2249458615251142\n",
      "iter_count:  649 the loss: 0.22137175312662027\n",
      "iter_count:  650 the loss: 0.2130806657003168\n",
      "iter_count:  651 the loss: 0.2125286257600701\n",
      "iter_count:  652 the loss: 0.2193951330522448\n",
      "iter_count:  653 the loss: 0.23869891161412818\n",
      "iter_count:  654 the loss: 0.2099559268725656\n",
      "iter_count:  655 the loss: 0.21022806990614618\n",
      "iter_count:  656 the loss: 0.2103243669485816\n",
      "iter_count:  657 the loss: 0.21073313828843485\n",
      "iter_count:  658 the loss: 0.2155889189781629\n",
      "iter_count:  659 the loss: 0.20993845462065264\n",
      "iter_count:  660 the loss: 0.24947138414271197\n",
      "iter_count:  661 the loss: 0.26748874475528134\n",
      "iter_count:  662 the loss: 0.2731345809784395\n",
      "iter_count:  663 the loss: 0.2343712245093922\n",
      "iter_count:  664 the loss: 0.21307651610796946\n",
      "iter_count:  665 the loss: 0.22540286389223416\n",
      "iter_count:  666 the loss: 0.2178523590103404\n",
      "iter_count:  667 the loss: 0.2108160551213545\n",
      "iter_count:  668 the loss: 0.21003875242616893\n",
      "iter_count:  669 the loss: 0.2146121663228283\n",
      "iter_count:  670 the loss: 0.21811415913509208\n",
      "iter_count:  671 the loss: 0.2195189356069554\n",
      "iter_count:  672 the loss: 0.21297454228154325\n",
      "iter_count:  673 the loss: 0.21169542697754934\n",
      "iter_count:  674 the loss: 0.21109305521632418\n",
      "iter_count:  675 the loss: 0.2110447947670926\n",
      "iter_count:  676 the loss: 0.21078592583334707\n",
      "iter_count:  677 the loss: 0.21135863633502538\n",
      "iter_count:  678 the loss: 0.21203492757674738\n",
      "iter_count:  679 the loss: 0.22818980751965495\n",
      "iter_count:  680 the loss: 0.2503405880141689\n",
      "iter_count:  681 the loss: 0.24583617039919384\n",
      "iter_count:  682 the loss: 0.23082670228584104\n",
      "iter_count:  683 the loss: 0.22473824627284858\n",
      "iter_count:  684 the loss: 0.2114481002205075\n",
      "iter_count:  685 the loss: 0.21143112409995957\n",
      "iter_count:  686 the loss: 0.21611436131309972\n",
      "iter_count:  687 the loss: 0.2105762197151694\n",
      "iter_count:  688 the loss: 0.21267046986986932\n",
      "iter_count:  689 the loss: 0.2629842917824304\n",
      "iter_count:  690 the loss: 0.2760558409349312\n",
      "iter_count:  691 the loss: 0.2889388270764343\n",
      "iter_count:  692 the loss: 0.25540736248960016\n",
      "iter_count:  693 the loss: 0.22515678934096892\n",
      "iter_count:  694 the loss: 0.22892370828449193\n",
      "iter_count:  695 the loss: 0.26140665609017144\n",
      "iter_count:  696 the loss: 0.2473005392189535\n",
      "iter_count:  697 the loss: 0.2204625312319035\n",
      "iter_count:  698 the loss: 0.23232350648367098\n",
      "iter_count:  699 the loss: 0.24441264385925313\n",
      "iter_count:  700 the loss: 0.2227114419686713\n",
      "iter_count:  701 the loss: 0.2584225781156002\n",
      "iter_count:  702 the loss: 0.2814009413349819\n",
      "iter_count:  703 the loss: 0.24583282691868943\n",
      "iter_count:  704 the loss: 0.221354328291976\n",
      "iter_count:  705 the loss: 0.21007739549690466\n",
      "iter_count:  706 the loss: 0.2121081505819679\n",
      "iter_count:  707 the loss: 0.20939321682423387\n",
      "iter_count:  708 the loss: 0.21793109788714787\n",
      "iter_count:  709 the loss: 0.21656110583702903\n",
      "iter_count:  710 the loss: 0.2453504934246594\n",
      "iter_count:  711 the loss: 0.22156229081849088\n",
      "iter_count:  712 the loss: 0.21153984122132166\n",
      "iter_count:  713 the loss: 0.270567855625277\n",
      "iter_count:  714 the loss: 0.20955713315729335\n",
      "iter_count:  715 the loss: 0.2093808475885127\n",
      "iter_count:  716 the loss: 0.21742908573615277\n",
      "iter_count:  717 the loss: 0.26429614780884114\n",
      "iter_count:  718 the loss: 0.2943725171757089\n",
      "iter_count:  719 the loss: 0.2810231718288499\n",
      "iter_count:  720 the loss: 0.24531643210680823\n",
      "iter_count:  721 the loss: 0.2757309995863047\n",
      "iter_count:  722 the loss: 0.27488703354216976\n",
      "iter_count:  723 the loss: 0.31273687590118393\n",
      "iter_count:  724 the loss: 0.23930393339191533\n",
      "iter_count:  725 the loss: 0.23239141919295203\n",
      "iter_count:  726 the loss: 0.2154548518425744\n",
      "iter_count:  727 the loss: 0.23236224594850013\n",
      "iter_count:  728 the loss: 0.21607301437117474\n",
      "iter_count:  729 the loss: 0.21094034512934487\n",
      "iter_count:  730 the loss: 0.2295045562616404\n",
      "iter_count:  731 the loss: 0.22103288328819481\n",
      "iter_count:  732 the loss: 0.2187408082297126\n",
      "iter_count:  733 the loss: 0.21307490158338438\n",
      "iter_count:  734 the loss: 0.21430992684956462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  735 the loss: 0.22118480511853061\n",
      "iter_count:  736 the loss: 0.20877501931155187\n",
      "iter_count:  737 the loss: 0.21123552014916222\n",
      "iter_count:  738 the loss: 0.20891664853625944\n",
      "iter_count:  739 the loss: 0.20940728484096552\n",
      "iter_count:  740 the loss: 0.24744431859746957\n",
      "iter_count:  741 the loss: 0.20999662646018616\n",
      "iter_count:  742 the loss: 0.24793183718021522\n",
      "iter_count:  743 the loss: 0.24528654354863413\n",
      "iter_count:  744 the loss: 0.21749197930293238\n",
      "iter_count:  745 the loss: 0.21214955864885096\n",
      "iter_count:  746 the loss: 0.22307393510381276\n",
      "iter_count:  747 the loss: 0.2333774366705749\n",
      "iter_count:  748 the loss: 0.24695920248727865\n",
      "iter_count:  749 the loss: 0.22235138963973616\n",
      "iter_count:  750 the loss: 0.22879553340947884\n",
      "iter_count:  751 the loss: 0.24744238906153246\n",
      "iter_count:  752 the loss: 0.2135131138663951\n",
      "iter_count:  753 the loss: 0.219840674802809\n",
      "iter_count:  754 the loss: 0.22265330602096817\n",
      "iter_count:  755 the loss: 0.22410144415934316\n",
      "iter_count:  756 the loss: 0.24609488909815405\n",
      "iter_count:  757 the loss: 0.2383560153476853\n",
      "iter_count:  758 the loss: 0.24702040278466406\n",
      "iter_count:  759 the loss: 0.23844400267839733\n",
      "iter_count:  760 the loss: 0.22115900027968188\n",
      "iter_count:  761 the loss: 0.21784033435336625\n",
      "iter_count:  762 the loss: 0.20865804415942632\n",
      "iter_count:  763 the loss: 0.21336491102270966\n",
      "iter_count:  764 the loss: 0.21338564358227768\n",
      "iter_count:  765 the loss: 0.2090802315823709\n",
      "iter_count:  766 the loss: 0.21468518562942493\n",
      "iter_count:  767 the loss: 0.22666774086161612\n",
      "iter_count:  768 the loss: 0.21112281563609067\n",
      "iter_count:  769 the loss: 0.22001687003913228\n",
      "iter_count:  770 the loss: 0.20926435573116323\n",
      "iter_count:  771 the loss: 0.20930650569756426\n",
      "iter_count:  772 the loss: 0.2108577321600992\n",
      "iter_count:  773 the loss: 0.21119304138509618\n",
      "iter_count:  774 the loss: 0.22408872174005529\n",
      "iter_count:  775 the loss: 0.2298278397665335\n",
      "iter_count:  776 the loss: 0.2206132487032657\n",
      "iter_count:  777 the loss: 0.2158441803552928\n",
      "iter_count:  778 the loss: 0.212334340113891\n",
      "iter_count:  779 the loss: 0.2153323027027388\n",
      "iter_count:  780 the loss: 0.21048851333111862\n",
      "iter_count:  781 the loss: 0.21514533659224863\n",
      "iter_count:  782 the loss: 0.2341036060865089\n",
      "iter_count:  783 the loss: 0.21865522756632516\n",
      "iter_count:  784 the loss: 0.2375584412826278\n",
      "iter_count:  785 the loss: 0.26521198724411865\n",
      "iter_count:  786 the loss: 0.2223129138905729\n",
      "iter_count:  787 the loss: 0.2115907874953352\n",
      "iter_count:  788 the loss: 0.27490251980847014\n",
      "iter_count:  789 the loss: 0.2376280640394017\n",
      "iter_count:  790 the loss: 0.2514730977005751\n",
      "iter_count:  791 the loss: 0.21161549778222574\n",
      "iter_count:  792 the loss: 0.20955747192223323\n",
      "iter_count:  793 the loss: 0.21284532339783677\n",
      "iter_count:  794 the loss: 0.22558948270614262\n",
      "iter_count:  795 the loss: 0.2478983064993888\n",
      "iter_count:  796 the loss: 0.21581466973825617\n",
      "iter_count:  797 the loss: 0.20813260599324734\n",
      "iter_count:  798 the loss: 0.20929539429683044\n",
      "iter_count:  799 the loss: 0.21771904539072842\n",
      "iter_count:  800 the loss: 0.21103199365571934\n",
      "iter_count:  801 the loss: 0.2078151425583437\n",
      "iter_count:  802 the loss: 0.20927904363349742\n",
      "iter_count:  803 the loss: 0.21914441685541297\n",
      "iter_count:  804 the loss: 0.23893566334159397\n",
      "iter_count:  805 the loss: 0.2266594041997896\n",
      "iter_count:  806 the loss: 0.2143934653932622\n",
      "iter_count:  807 the loss: 0.20913074221485278\n",
      "iter_count:  808 the loss: 0.20995440018708642\n",
      "iter_count:  809 the loss: 0.21645081979273495\n",
      "iter_count:  810 the loss: 0.23329102459846932\n",
      "iter_count:  811 the loss: 0.2844481289573072\n",
      "iter_count:  812 the loss: 0.20714160628257736\n",
      "iter_count:  813 the loss: 0.2095056451088606\n",
      "iter_count:  814 the loss: 0.21748253775938087\n",
      "iter_count:  815 the loss: 0.20774279781724864\n",
      "iter_count:  816 the loss: 0.23199629840872774\n",
      "iter_count:  817 the loss: 0.21864426574240708\n",
      "iter_count:  818 the loss: 0.2096661164443014\n",
      "iter_count:  819 the loss: 0.21651763822254436\n",
      "iter_count:  820 the loss: 0.20817586128582985\n",
      "iter_count:  821 the loss: 0.2124586664435743\n",
      "iter_count:  822 the loss: 0.2082030311421869\n",
      "iter_count:  823 the loss: 0.21179058311587728\n",
      "iter_count:  824 the loss: 0.2078185667214749\n",
      "iter_count:  825 the loss: 0.20783464984938602\n",
      "iter_count:  826 the loss: 0.20874614718666162\n",
      "iter_count:  827 the loss: 0.20890627654136132\n",
      "iter_count:  828 the loss: 0.2084934033563824\n",
      "iter_count:  829 the loss: 0.20845969991905702\n",
      "iter_count:  830 the loss: 0.2113646910382182\n",
      "iter_count:  831 the loss: 0.22846897281430312\n",
      "iter_count:  832 the loss: 0.2363983421397782\n",
      "iter_count:  833 the loss: 0.20811251711102333\n",
      "iter_count:  834 the loss: 0.2339010125600419\n",
      "iter_count:  835 the loss: 0.2318098410204007\n",
      "iter_count:  836 the loss: 0.23919854893636416\n",
      "iter_count:  837 the loss: 0.21878257841519416\n",
      "iter_count:  838 the loss: 0.2219126025822404\n",
      "iter_count:  839 the loss: 0.2994234929635033\n",
      "iter_count:  840 the loss: 0.258580257766245\n",
      "iter_count:  841 the loss: 0.2085319073480343\n",
      "iter_count:  842 the loss: 0.21402704179416635\n",
      "iter_count:  843 the loss: 0.21214367416993982\n",
      "iter_count:  844 the loss: 0.2232997303454717\n",
      "iter_count:  845 the loss: 0.2442863814522657\n",
      "iter_count:  846 the loss: 0.22195659396027434\n",
      "iter_count:  847 the loss: 0.22659744739413915\n",
      "iter_count:  848 the loss: 0.2407508544075557\n",
      "iter_count:  849 the loss: 0.20866834812436594\n",
      "iter_count:  850 the loss: 0.20878046923229499\n",
      "iter_count:  851 the loss: 0.21156381637607014\n",
      "iter_count:  852 the loss: 0.20847268217324652\n",
      "iter_count:  853 the loss: 0.20956956836112406\n",
      "iter_count:  854 the loss: 0.21467759274937395\n",
      "iter_count:  855 the loss: 0.22614501070237317\n",
      "iter_count:  856 the loss: 0.24876583119656906\n",
      "iter_count:  857 the loss: 0.24785654270537413\n",
      "iter_count:  858 the loss: 0.23644892898683476\n",
      "iter_count:  859 the loss: 0.217448662944381\n",
      "iter_count:  860 the loss: 0.21349052673290977\n",
      "iter_count:  861 the loss: 0.20867124055684805\n",
      "iter_count:  862 the loss: 0.23214273677744762\n",
      "iter_count:  863 the loss: 0.21729436317547599\n",
      "iter_count:  864 the loss: 0.21095182999000492\n",
      "iter_count:  865 the loss: 0.22248765508243823\n",
      "iter_count:  866 the loss: 0.20880464281027486\n",
      "iter_count:  867 the loss: 0.2255377712552243\n",
      "iter_count:  868 the loss: 0.2174215623326474\n",
      "iter_count:  869 the loss: 0.23428195386445935\n",
      "iter_count:  870 the loss: 0.2122927492829902\n",
      "iter_count:  871 the loss: 0.21785415133103594\n",
      "iter_count:  872 the loss: 0.2089634024160855\n",
      "iter_count:  873 the loss: 0.21414697548073644\n",
      "iter_count:  874 the loss: 0.20889479833956648\n",
      "iter_count:  875 the loss: 0.2127186281239432\n",
      "iter_count:  876 the loss: 0.2263988838390345\n",
      "iter_count:  877 the loss: 0.21270563212398808\n",
      "iter_count:  878 the loss: 0.21888226830382965\n",
      "iter_count:  879 the loss: 0.2089175078928503\n",
      "iter_count:  880 the loss: 0.20852325285223358\n",
      "iter_count:  881 the loss: 0.21114277896532913\n",
      "iter_count:  882 the loss: 0.24595614236436475\n",
      "iter_count:  883 the loss: 0.22851659196435922\n",
      "iter_count:  884 the loss: 0.2519936418665384\n",
      "iter_count:  885 the loss: 0.2079975848122842\n",
      "iter_count:  886 the loss: 0.21280024033091777\n",
      "iter_count:  887 the loss: 0.21281524091785448\n",
      "iter_count:  888 the loss: 0.22592015125723708\n",
      "iter_count:  889 the loss: 0.23652731414246178\n",
      "iter_count:  890 the loss: 0.21595695277939628\n",
      "iter_count:  891 the loss: 0.22932613289257067\n",
      "iter_count:  892 the loss: 0.2273193532443826\n",
      "iter_count:  893 the loss: 0.23927379883780814\n",
      "iter_count:  894 the loss: 0.21878167166799742\n",
      "iter_count:  895 the loss: 0.2174023390497807\n",
      "iter_count:  896 the loss: 0.23448959532735975\n",
      "iter_count:  897 the loss: 0.24311321815344583\n",
      "iter_count:  898 the loss: 0.21930654053652776\n",
      "iter_count:  899 the loss: 0.2238088120301296\n",
      "iter_count:  900 the loss: 0.2277061402299842\n",
      "iter_count:  901 the loss: 0.2503074729772941\n",
      "iter_count:  902 the loss: 0.26595112585654673\n",
      "iter_count:  903 the loss: 0.2145794502478052\n",
      "iter_count:  904 the loss: 0.20645083458182936\n",
      "iter_count:  905 the loss: 0.21285890818496156\n",
      "iter_count:  906 the loss: 0.2073864004066727\n",
      "iter_count:  907 the loss: 0.20676589196445522\n",
      "iter_count:  908 the loss: 0.21407151354792542\n",
      "iter_count:  909 the loss: 0.2073009082430021\n",
      "iter_count:  910 the loss: 0.20664575684510306\n",
      "iter_count:  911 the loss: 0.20938545440127707\n",
      "iter_count:  912 the loss: 0.20738355180580284\n",
      "iter_count:  913 the loss: 0.20728385518975806\n",
      "iter_count:  914 the loss: 0.20784995800344316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_count:  915 the loss: 0.2072863141068711\n",
      "iter_count:  916 the loss: 0.20786658356974513\n",
      "iter_count:  917 the loss: 0.24755166175966944\n",
      "iter_count:  918 the loss: 0.20824709648933046\n",
      "iter_count:  919 the loss: 0.21214034693319564\n",
      "iter_count:  920 the loss: 0.2169236088703005\n",
      "iter_count:  921 the loss: 0.23540362449116164\n",
      "iter_count:  922 the loss: 0.25351285145077546\n",
      "iter_count:  923 the loss: 0.23138474261777486\n",
      "iter_count:  924 the loss: 0.21580239617153454\n",
      "iter_count:  925 the loss: 0.20660138636510342\n",
      "iter_count:  926 the loss: 0.21396483601933758\n",
      "iter_count:  927 the loss: 0.20584834617843528\n",
      "iter_count:  928 the loss: 0.2089856181085758\n",
      "iter_count:  929 the loss: 0.22063036265323896\n",
      "iter_count:  930 the loss: 0.2081032539736252\n",
      "iter_count:  931 the loss: 0.22375953320721453\n",
      "iter_count:  932 the loss: 0.21222759118331963\n",
      "iter_count:  933 the loss: 0.20756496941497474\n",
      "iter_count:  934 the loss: 0.22737749485165507\n",
      "iter_count:  935 the loss: 0.2475157767359467\n",
      "iter_count:  936 the loss: 0.2203389030415895\n",
      "iter_count:  937 the loss: 0.20580214088633417\n",
      "iter_count:  938 the loss: 0.20962320271894352\n",
      "iter_count:  939 the loss: 0.23305110599384293\n",
      "iter_count:  940 the loss: 0.20893393906954558\n",
      "iter_count:  941 the loss: 0.20572403447121954\n",
      "iter_count:  942 the loss: 0.20870059970575836\n",
      "iter_count:  943 the loss: 0.2060557992302858\n",
      "iter_count:  944 the loss: 0.20580313371663714\n",
      "iter_count:  945 the loss: 0.23772610435715194\n",
      "iter_count:  946 the loss: 0.21574653562942273\n",
      "iter_count:  947 the loss: 0.24316945429232611\n",
      "iter_count:  948 the loss: 0.22396832482661333\n",
      "iter_count:  949 the loss: 0.2218014654016906\n",
      "iter_count:  950 the loss: 0.2362730535418498\n",
      "iter_count:  951 the loss: 0.22444628239714107\n",
      "iter_count:  952 the loss: 0.23318694460706543\n",
      "iter_count:  953 the loss: 0.25668973464800793\n",
      "iter_count:  954 the loss: 0.24582884401080077\n",
      "iter_count:  955 the loss: 0.2913665347813668\n",
      "iter_count:  956 the loss: 0.32960566308889017\n",
      "iter_count:  957 the loss: 0.2121730694274482\n",
      "iter_count:  958 the loss: 0.20593458588150848\n",
      "iter_count:  959 the loss: 0.21010563414150954\n",
      "iter_count:  960 the loss: 0.21207425503495897\n",
      "iter_count:  961 the loss: 0.2082845913449806\n",
      "iter_count:  962 the loss: 0.206639655086247\n",
      "iter_count:  963 the loss: 0.2071963556928699\n",
      "iter_count:  964 the loss: 0.2506473259546729\n",
      "iter_count:  965 the loss: 0.27597330625195526\n",
      "iter_count:  966 the loss: 0.3062734689811702\n",
      "iter_count:  967 the loss: 0.2632595350851743\n",
      "iter_count:  968 the loss: 0.23454214365713796\n",
      "iter_count:  969 the loss: 0.25432740039914825\n",
      "iter_count:  970 the loss: 0.20656640714532842\n",
      "iter_count:  971 the loss: 0.20674137919243643\n",
      "iter_count:  972 the loss: 0.20924909355869425\n",
      "iter_count:  973 the loss: 0.22115506784307593\n",
      "iter_count:  974 the loss: 0.26261232980015903\n",
      "iter_count:  975 the loss: 0.23136945440628767\n",
      "iter_count:  976 the loss: 0.21438309562445695\n",
      "iter_count:  977 the loss: 0.23930684527694734\n",
      "iter_count:  978 the loss: 0.27190052355544847\n",
      "iter_count:  979 the loss: 0.24290274884398974\n",
      "iter_count:  980 the loss: 0.22588958701406944\n",
      "iter_count:  981 the loss: 0.21800364198085198\n",
      "iter_count:  982 the loss: 0.2293397373773016\n",
      "iter_count:  983 the loss: 0.25090115370185295\n",
      "iter_count:  984 the loss: 0.2923114623204592\n",
      "iter_count:  985 the loss: 0.2611981792514882\n",
      "iter_count:  986 the loss: 0.21130971467326254\n",
      "iter_count:  987 the loss: 0.225154728474305\n",
      "iter_count:  988 the loss: 0.22091666986669709\n",
      "iter_count:  989 the loss: 0.2097426339572734\n",
      "iter_count:  990 the loss: 0.22654398845388124\n",
      "iter_count:  991 the loss: 0.21075171630238554\n",
      "iter_count:  992 the loss: 0.20823379349571702\n",
      "iter_count:  993 the loss: 0.22706927047850392\n",
      "iter_count:  994 the loss: 0.2099213009108403\n",
      "iter_count:  995 the loss: 0.2718006967702066\n",
      "iter_count:  996 the loss: 0.336995272357931\n",
      "iter_count:  997 the loss: 0.36928418498184457\n",
      "iter_count:  998 the loss: 0.2999852252359287\n",
      "iter_count:  999 the loss: 0.2873768081553153\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26234133  0.21210592]\n"
     ]
    }
   ],
   "source": [
    "#Loss function\n",
    "#拟合函数 e^ui = w|r^ui - y|\n",
    "#     x1 = np.linspace(0, 9, sample_num)\n",
    "#     x2 = np.linspace(4, 13, sample_num)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import style\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def SGD(predicted_matrix, eui_hat, step_size=2, max_iter_count=1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param samples: 样本\n",
    "    :param y: 结果value\n",
    "    :param step_size: 每一接迭代的步长\n",
    "    :param max_iter_count: 最大的迭代次数\n",
    "    :param batch_size: 随机选取的相对于总样本的大小\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m, var = predicted_matrix.shape \n",
    "    theta = np.zeros(2) \n",
    "    print(theta)\n",
    "    eui_hat = eui_hat.flatten()\n",
    "    loss = 1\n",
    "    iter_count = 0\n",
    "    iter_list=[]\n",
    "    loss_list=[]\n",
    "    theta1=[]\n",
    "    theta2=[]\n",
    "    \n",
    "    while loss > 0.01 and iter_count < max_iter_count:\n",
    "        loss = 0\n",
    "        theta1.append(theta[0])\n",
    "        theta2.append(theta[1])\n",
    "        rand1 = np.random.randint(0,m,1)\n",
    "        h = np.dot(theta,predicted_matrix[rand1].T)\n",
    "        \n",
    "        for i in range(len(theta)):\n",
    "            theta[i] =theta[i] - step_size*(1/m)*(h - eui_hat[rand1])*predicted_matrix[rand1,i]\n",
    "        for i in range(m):\n",
    "            h = np.dot(theta.T, predicted_matrix[i])\n",
    "            every_loss = (1/(var*m))*np.power((h - eui_hat[i]), 2)\n",
    "            loss = loss + every_loss\n",
    "            \n",
    "        print(\"iter_count: \", iter_count, \"the loss:\", loss)\n",
    "        \n",
    "        iter_list.append(iter_count)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        iter_count += 1\n",
    "\n",
    "    plt.plot(iter_list,loss_list)\n",
    "    plt.xlabel(\"iter\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "    return theta1,theta2,theta,loss_list\n",
    "\n",
    "\n",
    "def get_data(sample_num=1000):\n",
    "    x1 = np.linspace(0, 9, sample_num)\n",
    "    x2 = np.linspace(4, 13, sample_num)\n",
    "    x = np.concatenate(([x1], [x2]), axis=0).T\n",
    "    y = 0.5 * (np.ma.abs(np.ma.subtract(x, 4.5))) ## 拟合函数，\n",
    "   \n",
    "    \n",
    "   \n",
    "   \n",
    "    return x, y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "   \n",
    "    predicted_matrix,eui_hat = get_data()\n",
    "   \n",
    "    theta1,theta2,theta,loss_list = SGD(predicted_matrix, eui_hat)\n",
    "    print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a0ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0e7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37037406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import style\n",
    "\n",
    "def get_data(sample_num=2000):\n",
    "    x1 = np.linspace(0, 9, sample_num)\n",
    "    x2 = np.linspace(4, 13, sample_num)\n",
    "    x = np.concatenate(([x1], [x2]), axis=0).T\n",
    "    y = np.dot(x, np.array([5, 7]).T) ## 拟合函数，示例是 y = 5*x1 + 7*x2\n",
    "   \n",
    "    return x, y\n",
    "\n",
    "\n",
    "    \n",
    "def SGD(samples, y, step_size=2, max_iter_count=2000):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param samples: 样本\n",
    "    :param y: 结果value\n",
    "    :param step_size: 每一接迭代的步长\n",
    "    :param max_iter_count: 最大的迭代次数\n",
    "    :param batch_size: 随机选取的相对于总样本的大小\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    m, var = samples.shape\n",
    "    theta = np.zeros(2)\n",
    "    y = y.flatten()\n",
    "    loss = 1\n",
    "    iter_count = 0\n",
    "    iter_list=[]\n",
    "    loss_list=[]\n",
    "    theta1=[]\n",
    "    theta2=[]\n",
    "    \n",
    "    while loss > 0.01 and iter_count < max_iter_count:\n",
    "        loss = 0\n",
    "        theta1.append(theta[0])\n",
    "        theta2.append(theta[1])\n",
    "        rand1 = np.random.randint(0,m,1)\n",
    "        h = np.dot(theta,samples[rand1].T)\n",
    "        \n",
    "        for i in range(len(theta)):\n",
    "            theta[i] =theta[i] - step_size*(1/m)*(h - y[rand1])*samples[rand1,i]\n",
    "        for i in range(m):\n",
    "            h = np.dot(theta.T, samples[i])\n",
    "            every_loss = (1/(var*m))*np.power((h - y[i]), 2)\n",
    "            loss = loss + every_loss\n",
    "            \n",
    "        print(\"iter_count: \", iter_count, \"the loss:\", loss)\n",
    "        \n",
    "        iter_list.append(iter_count)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        iter_count += 1\n",
    "\n",
    "    plt.plot(iter_list,loss_list)\n",
    "    plt.xlabel(\"iter\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "    return theta1,theta2,theta,loss_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    samples, y = get_data()\n",
    "    theta1,theta2,theta,loss_list = SGD(samples, y)\n",
    "    print(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a697d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import style\n",
    "\n",
    "def get_data(sample_num=10):\n",
    "    x1 = np.linspace(0, 9, sample_num)\n",
    "    x2 = np.linspace(4, 13, sample_num)\n",
    "    x = np.concatenate(([x1], [x2]), axis=0).T\n",
    "    print(x)\n",
    "    y = np.dot(x, np.array([5, 7]).T) ## 拟合函数，示例是 y = 5*x1 + 7*x2\n",
    "    print(y)\n",
    "    return x, y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    samples, y = get_data()\n",
    "    #theta1,theta2,theta,loss_list = SGD(samples, y)\n",
    "    #print(theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
